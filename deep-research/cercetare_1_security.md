---
conversie_roland: true
data: 2025-08-14
caractere: 73097
cuvinte: 10769
tokeni_estimati: 18275
optimizat_pentru: AI (Claude/GPT)
---

Implementarea Foundation & Security + ADN #1 (Context Specializat)
Pentru sistemul de traduceri AI descris, vom implementa complet È™i la standard enterprise toate funcÈ›ionalitÄƒÈ›ile critice de securitate, compliance GDPR È™i context specializat, folosind exclusiv soluÈ›ii open-source self-hosted. Abordarea È›inteÈ™te rezolvarea vulnerabilitÄƒÈ›ilor identificate (lipsa verificÄƒrii webhook, rate limiting, È™tergere date, etc.)[1] È™i adaugÄƒ mecanisme avansate de adaptare a traducerii la contextul documentului (ADN #1) pentru acurateÈ›e sporitÄƒ È™i monetizare superioarÄƒ[2][3]. Toate componentele vor fi integrate Ã®n stack-ul existent (Flask backend, SQLite, local files) fÄƒrÄƒ costuri suplimentare sau servicii cloud, conform cerinÈ›elor.
ğŸ›¡ï¸ Componenta 1: Security Fixes (SoluÈ›ii Open-Source)
Componenta de securitate va consolida aplicaÈ›ia Ã®mpotriva fraudelor È™i abuzurilor, acoperind trei puncte critice: verificarea semnÄƒturii webhooks Stripe, limitarea ratei de acces È™i gestionarea Ã®n siguranÈ›Äƒ a upload-urilor. Aceste mÄƒsuri au fost prioritizate drept esenÈ›iale[4] pentru a preveni plÄƒÈ›i false, atacuri DoS È™i breÈ™e de fiÈ™iere. Se folosesc doar biblioteci gratuite (ex. modul hmac, Redis open-source, Flask standard) È™i stocare localÄƒ, respectÃ¢nd cerinÈ›ele de zero cost.
1.1 Verificare Webhook HMAC (Stripe)
â€¢	Validare semnÄƒturÄƒ Stripe: ImplementÄƒm un middleware Flask (sau decorator pe ruta de webhook) care verificÄƒ semnÄƒtura HMAC SHA256 a fiecÄƒrui webhook Stripe primit, folosind secretul endpoint-ului Stripe. Stripe include un header Stripe-Signature ce conÈ›ine timestamp È™i semnÄƒturi. Middleware-ul va extrage timestamp-ul È™i semnÄƒtura din header È™i va calcula HMAC-ul folosind payload-ul brut al cererii (exact cum a fost primit, fÄƒrÄƒ prelucrÄƒri) È™i secretul cunoscut. Se foloseÈ™te hashlib.sha256 È™i hmac (din biblioteca standard Python) pentru a genera semnÄƒtura aÈ™teptatÄƒ, care apoi este comparatÄƒ Ã®n mod securizat (hmac.compare_digest) cu semnÄƒtura trimisÄƒ de Stripe[5]. Ãn acest mod ne asigurÄƒm cÄƒ evenimentul provine Ã®ntr-adevÄƒr de la Stripe È™i nu a fost modificat Ã®n tranzit[6].
â€¢	ToleranÈ›Äƒ timp 300s: Vom verifica È™i timestamp-ul semnÄƒturii pentru a preveni replay attacks. DacÄƒ diferenÈ›a dintre timestamp (trimis de Stripe) È™i ora serverului depÄƒÈ™eÈ™te 300 de secunde (5 minute), webhook-ul este respins ca fiind expirat, chiar dacÄƒ semnÄƒtura HMAC corespunde[5]. AceastÄƒ toleranÈ›Äƒ de 5 minute este conform practicilor Stripe (default al librÄƒriilor oficiale) È™i Ã®mpiedicÄƒ un atacator sÄƒ reutilizeze o cerere veche[7].
â€¢	Integrare cu Stripe SDK (optional): Pentru robusteÈ›e, putem folosi È™i metoda oferitÄƒ de librÄƒria oficialÄƒ Stripe (care este gratuitÄƒ) â€“ de exemplu stripe.Webhook.construct_event(payload, sig_header, secret, tolerance=300) â€“ care aruncÄƒ o excepÈ›ie dacÄƒ semnÄƒtura nu valideazÄƒ. Ãn orice caz, implementarea manualÄƒ de mai sus asigurÄƒ independenÈ›a de librÄƒrii externe È™i respectÄƒ exact mecanismul HMAC Stripe.
â€¢	Error handling È™i logging: DacÄƒ verificarea eÈ™ueazÄƒ (semnÄƒturÄƒ invalidÄƒ sau timp expirat), serverul va returna imediat un HTTP 400 È™i nu va procesa evenimentul. Vom loga incidentul Ã®ntr-un fiÈ™ier local de jurnal (ex: logs/webhook_errors.log) cu detalii (timestamp, IP, event id, motiv) pentru audit È™i debugging. Logging-ul local garanteazÄƒ pÄƒstrarea unei urme a tentativelor eÈ™uate, Ã®mbunÄƒtÄƒÈ›ind capacitatea de auditare a securitÄƒÈ›ii.
â€¢	Idempotency tracking: Vom introduce un mecanism de idempotency pentru webhook-uri, pentru a evita procesarea dublÄƒ a aceluiaÈ™i eveniment Stripe (de ex., situaÈ›ia Ã®n care Stripe retrimite event-ul sau Ã®l primim de douÄƒ ori din eroare de reÈ›ea). Concret, Ã®n SQLite vom avea o tabelÄƒ processed_webhooks(event_id TEXT PRIMARY KEY, processed_at DATETIME) unde memorÄƒm ID-urile evenimentelor Stripe deja procesate cu succes[8]. La recepÈ›ia unui webhook valid, se verificÄƒ Ã®n baza de date dacÄƒ event_id existÄƒ deja; dacÄƒ da, se ignorÄƒ (returnÃ¢nd 200 OK imediat pentru a opri retry-ul Stripe), dacÄƒ nu, se proceseazÄƒ È™i se insereazÄƒ ID-ul Ã®n tabel. Acest tracking local ne protejeazÄƒ de double-charging sau acÈ›iuni repetate accidental[9].
â€¢	Rate limiting pentru webhook (dedicat): DeÈ™i webhook-urile vin de la Stripe, vom adÄƒuga È™i un rate limit specific pe endpoint-ul de webhook ca strat suplimentar. De exemplu, acceptÄƒm max. 10 cereri/minut pe ruta Stripe Webhook, ceea ce este mult peste rata normalÄƒ Stripe, dar previne flood-ul deliberat (Ã®n caz cÄƒ un atacator descoperÄƒ URL-ul webhook). Limitarea se va implementa tot cu Redis (vezi secÈ›iunea 1.2) Ã®nsÄƒ pe un key separat global (nu pe IP, deoarece Stripe foloseÈ™te IP-uri variate) sau folosind un token global. Ãn plus, se poate valida È™i IP-ul sursÄƒ al cererii pentru a accepta doar range-urile cunoscute Stripe (opÈ›ional, pentru extra securitate).
Ãn concluzie, dupÄƒ acest pas, webhook-urile de platÄƒ sunt securizate: doar evenimente Stripe reale, recente È™i neprocesate anterior vor fi luate Ã®n calcul[10].
1.2 Rate Limiting cu Redis (Local)
â€¢	InstanÈ›Äƒ Redis localÄƒ: Vom folosi Redis instalat local (ruleazÄƒ ca serviciu pe server sau container Docker) pentru a implementa limitarea de ratÄƒ. Redis este open-source È™i foarte eficient pentru contoare cu expirare, astfel Ã®ncÃ¢t nu introducem dependenÈ›e cloud. DacÄƒ se foloseÈ™te Docker Compose, vom adÄƒuga un serviciu Redis care sÄƒ fie accesibil doar intern (localhost) pentru aplicaÈ›ia Flask.
â€¢	Limitare globalÄƒ API: Vom aplica o regulÄƒ de rate limiting de 5 cereri pe minut per adresÄƒ IP pentru endpoint-urile sensibile ale aplicaÈ›iei (ex: endpoint-ul de traducere efectivÄƒ sau de preview) â€“ exact pragul recomandat anterior pentru prevenirea abuzului[8][11]. Implementarea se face astfel: la fiecare request, se formeazÄƒ o cheie Redis de forma rl:<IP>:<endpoint> È™i se executÄƒ operaÈ›ia atomica INCR pe acea cheie, cu setare de expirare la 60 secunde dacÄƒ cheia nu existÄƒ. DacÄƒ valoarea returnatÄƒ de INCR depÄƒÈ™eÈ™te 5, atunci limita a fost atinsÄƒ È™i vom bloca cererea (status 429 Too Many Requests). Altfel, lÄƒsÄƒm execuÈ›ia normalÄƒ. Deoarece Redis INCR cu expirare este atomic, aceastÄƒ soluÈ›ie va funcÈ›iona corect chiar È™i sub concurenÈ›Äƒ ridicatÄƒ. Limitele concrete (5/minut) pot fi ajustate uÈ™or dintr-un fiÈ™ier de configurare YAML.
â€¢	LimitÄƒ specialÄƒ pentru preview: Conform cerinÈ›elor, vom adÄƒuga o limitare mai strictÄƒ pentru cererile de preview gratuit â€“ de exemplu maximum 2 preview-uri pe zi per IP. Aceasta previne abuzul de previzualizÄƒri gratuite (evitÃ¢nd ca un utilizator neautentificat sÄƒ obÈ›inÄƒ traduceri bucÄƒÈ›ite gratuit). Tehnic, implementÄƒm similar: cheie Redis preview:<IP> cu expirare 24h È™i limitare la 2. DacÄƒ un IP solicitÄƒ a 3-a previzualizare Ã®n aceeaÈ™i zi, i se refuzÄƒ cererea cu un mesaj de tip "LimitÄƒ de previzualizÄƒri atinsÄƒ, reveniÈ›i mÃ¢ine". AceastÄƒ regulÄƒ Ã®ncurajeazÄƒ utilizatorii sÄƒ treacÄƒ la variante plÄƒtite dacÄƒ depÄƒÈ™esc numÄƒrul de preview gratuit.
â€¢	Whitelist clienÈ›i premium: Vom permite definirea unei liste albe de clienÈ›i (identificaÈ›i dupÄƒ IP sau, mai bine, dupÄƒ un token API/client ID dacÄƒ existÄƒ autentificare) care sÄƒ fie scutiÈ›i de limitÄƒrile de mai sus. AceÈ™ti clienÈ›i premium (de ex. corporate clients sau administratorul) pot fi listaÈ›i Ã®ntr-un fiÈ™ier local de configurare (ex: config/whitelist.yaml cu IP-uri sau ID-uri exceptate). La verificarea rate-limit, dacÄƒ IP-ul se aflÄƒ Ã®n whitelist, regula este omisÄƒ. Astfel, clienÈ›ii plÄƒtitori pot beneficia de throughput mai mare conform abonamentelor lor.
â€¢	Banare temporarÄƒ IP: Vom extinde sistemul de rate-limit cu un mecanism de ban temporar pentru IP-urile care continuÄƒ sÄƒ trimitÄƒ cereri excesive. De exemplu, dacÄƒ un IP a fost blocat de 3 ori Ã®ntr-un interval scurt (sau depÄƒÈ™eÈ™te de N ori limita), putem considera comportament maliÈ›ios È™i Ã®l banÄƒm pentru o perioadÄƒ (ex: 1 orÄƒ). Implementare: menÈ›inem Ã®n SQLite o tabelÄƒ banned_ips(ip, ban_until). CÃ¢nd un IP atinge pragul de ban, inserÄƒm/actualizÄƒm intrarea cu timestamp-ul de expirare a ban-ului (ex: current_time + 1 orÄƒ). La fiecare request, Ã®nainte de verificarea Redis, consultÄƒm SQLite pentru a vedea dacÄƒ IP-ul este listat ca banat È™i dacÄƒ perioada nu a expirat. DacÄƒ da, returnÄƒm direct 429/403 È™i nu incrementÄƒm contorul. Acest ban persistÄƒ È™i dacÄƒ serverul reporneÈ™te (datoritÄƒ stocÄƒrii pe disc). Unscript de unban automat poate rula periodic (sau la fiecare request putem È™terge intrÄƒrile expirate). Astfel, un atacator va fi temporar blocat dupÄƒ abuz repetat, protejÃ¢nd infrastructura.
â€¢	Implementare Flask: Putem integra rate-limiter-ul folosind fie un middleware WSGI care intercepteazÄƒ toate request-urile (È™i decide pe baza PATH ce reguli se aplicÄƒ), fie folosind un decorator @limit pe anumite rute. ExistÄƒ È™i extensii ca flask-limiter, dar vom implementa manual pentru control deplin È™i dependenÈ›e minime. Logica de Redis È™i ban va fi Ã®ncapsulatÄƒ eventual Ã®ntr-un utilitar rate_limit.py apelat din routes.
â€¢	Logging È™i configurare: Toate evenimentele de limitÄƒ depÄƒÈ™itÄƒ sau ban vor fi logate (Ã®n JSON log, vezi secÈ›iunea 2.3) cu detalii (IP, endpoint, acÈ›iune luatÄƒ) pentru analizÄƒ ulterioarÄƒ. Limitele (numere, ferestre de timp), durata ban-ului È™i whitelist-ul sunt configurabile via YAML, astfel Ã®ncÃ¢t pot fi uÈ™or ajustate fÄƒrÄƒ modificare de cod.
Prin aceastÄƒ componentÄƒ, sistemul va preveni suprasolicitarea È™i atacurile de tip brute-force/DDoS la nivel de API, conform best-practices. Limita de 5 req/min/IP propusÄƒ previne abuzul fÄƒrÄƒ a impacta utilizatorii legitimi obiÈ™nuiÈ›i[11].
1.3 Upload Local cu Validare È™i Securizare
â€¢	ÃncÄƒrcare direct pe server (fÄƒrÄƒ cloud): Ãn locul folosirii unor URL-uri semnate S3 (cum era recomandat pentru securitate Ã®n variantÄƒ enterprise)[10], vom permite upload-ul fiÈ™ierelor direct pe serverul local, Ã®nsÄƒ cu mÄƒsuri stricte de validare server-side. FiÈ™ierele Ã®ncÄƒrcate vor fi salvate Ã®ntr-un director local securizat (ex. uploads/[12]) pe acelaÈ™i server, eliminÃ¢nd dependenÈ›ele de servicii externe de stocare. Directorul uploads/ va fi protejat astfel Ã®ncÃ¢t fiÈ™ierele sÄƒ nu fie accesibile direct prin URL public (neconfigurat ca static serving), ci doar prin procesele interne de traducere/livrare.
â€¢	Validare tip MIME È™i extensie: La primirea unui fiÈ™ier, serverul va verifica cÄƒ tipul de fiÈ™ier este permis È™i corespunde conÈ›inutului. Se defineÈ™te o listÄƒ de extensii acceptate (e.g. .pdf, .docx, .xlsx, .txt, .csv etc. â€“ sistemul suportÄƒ mai multe formate[13]). Vom folosi werkzeug.utils.secure_filename pentru a normaliza numele fiÈ™ierului (Ã®nlÄƒturÃ¢nd caractere periculoase) È™i vom verifica extensia. Ãn plus, pentru siguranÈ›Äƒ, determinÄƒm È™i tipul MIME real al fiÈ™ierului â€“ fie folosind Python mimetypes/python-magic (dacÄƒ e instalabil gratuit) â€“ pentru a preveni situaÈ›ii de tip â€œpolyglotâ€ (ex: fiÈ™ier .pdf fals care este de fapt script). DacÄƒ tipul real nu corespunde cu extensia aÈ™teptatÄƒ sau nu este Ã®n whitelist, upload-ul este respins cu eroare. De asemenea, se impune È™i o limitÄƒ de mÄƒrime (ex: max 50MB per fiÈ™ier, configurabil) â€“ fiÈ™ierele mai mari vor fi refuzate cu un mesaj de eroare, prevenind atÃ¢t abuzul de stocare cÃ¢t È™i eventuale probleme de performanÈ›Äƒ.
â€¢	Stocare securizatÄƒ: FiÈ™ierul validat este salvat Ã®n uploads/ sub un nume unic. Ca bunÄƒ practicÄƒ, putem genera un UUID sau hash din conÈ›inut ca nume de fiÈ™ier, Ã®n loc sÄƒ folosim numele original, evitÃ¢nd coliziuni È™i ascunzÃ¢nd informaÈ›ii despre fiÈ™ier. De exemplu, dacÄƒ userul Ã®ncarcÄƒ Contract.docx, Ã®l salvÄƒm ca uploads/abcd1234.docx È™i reÈ›inem maparea Ã®n baza de date (sau Ã®n sesiune). Astfel, chiar dacÄƒ cineva ar ghici calea, nu poate obÈ›ine fiÈ™ierul fÄƒrÄƒ un ID greu de ghicit. Ãn plus, vom seta permisiunile fiÈ™ierelor pe disc astfel Ã®ncÃ¢t doar userul sistem (sau procesul Flask) sÄƒ poatÄƒ citi/È™terge, È™i nu sunt executabile.
â€¢	Integrare cu backend-ul existent: Procesul de upload va fi gestionat probabil de o rutÄƒ Flask /upload definitÄƒ Ã®n backend/app.py sau un blueprint dedicat. DupÄƒ salvare, se va apela logica de procesare document (document_processor.py) pentru a extrage textul È™i calcula numÄƒrul de cuvinte/pagini[14]. Fluxul continuÄƒ apoi cu generarea preview-ului È™i afiÈ™area costului. AdaptÄƒm minimal codul existent: Ã®nlocuim eventualul upload anterior (dacÄƒ era direct Ã®n memorie sau alt sistem) cu acesta local, asigurÃ¢nd compatibilitatea cu restul pipeline-ului.
â€¢	Cleanup automat al fiÈ™ierelor: DupÄƒ ce fiÈ™ierul a fost procesat È™i tradus, vom decide politica de retenÈ›ie conform GDPR (vezi 2.1). Pe termen scurt, putem È™terge imediat fiÈ™ierele temporare care nu mai sunt necesare (ex: fiÈ™iere intermediare de extragere text, dacÄƒ existÄƒ). Pe termen mediu, fiÈ™ierul sursÄƒ original rÄƒmÃ¢ne stocat pÃ¢nÄƒ la 30 de zile (conform retenÈ›iei) pentru posibile download-uri ulterioare sau verificÄƒri, urmÃ¢nd a fi È™ters automat. De asemenea, dacÄƒ un utilizator anuleazÄƒ comanda sau nu finalizeazÄƒ plata, fiÈ™ierul Ã®ncÄƒrcat poate fi eliminat mai devreme (ex: dupÄƒ 24h) pentru a elibera spaÈ›iu, Ã®ntrucÃ¢t nu mai e nevoie de el.
â€¢	FÄƒrÄƒ dependenÈ›e externe riscante: Gestionarea fiÈ™ierelor va fi realizatÄƒ doar cu cod Python nativ È™i biblioteci standard (os, shutil etc.). Nu vom folosi servicii third-party de scanare sau stocare cloud. OpÈ›ional, pentru securitate sporitÄƒ, se poate integra un antivirus open-source (ClamAV) pe server pentru a scana fiÈ™ierele Ã®ncÄƒrcate de viruÈ™i macro sau scripturi, Ã®nsÄƒ acest pas este opÈ›ional È™i poate fi menÈ›ionat Ã®n checklist-ul de securitate.
â€¢	Logging upload & errors: Fiecare upload va fi logat (nume original, noul ID, user/email, timp) Ã®n log-ul audit, iar erorile de validare (tip invalid, oversize) vor fi È™i ele Ã®nregistrate pentru a monitoriza tentativele eÈ™uate sau potenÈ›iale atacuri (ex: cineva Ã®ncercÃ¢nd sÄƒ urce .exe).
Prin aceste mÄƒsuri, upload-ul local devine securizat: acceptÄƒm doar tipuri de fiÈ™iere cunoscute È™i sigure, prevenim injectarea de conÈ›inut malitios È™i stocÄƒm fiÈ™ierele Ã®n mod izolat. Chiar dacÄƒ iniÈ›ial se recomanda upload direct Ã®n cloud cu URL presigned pentru siguranÈ›Äƒ[10], soluÈ›ia noastrÄƒ localÄƒ oferÄƒ un nivel similar de securitate prin validare strictÄƒ È™i izolare, fÄƒrÄƒ costuri.
ğŸ›¡ï¸ Componenta 2: GDPR Compliance (Basic, Self-Hosted)
Pentru alinierea la GDPR, implementÄƒm mecanisme de È™tergere automatÄƒ a datelor, portal de acces/È™tergere a datelor pentru clienÈ›i (DSAR) È™i logging audit â€“ toate local, fÄƒrÄƒ servicii externe, conform cerinÈ›elor. Aceste funcÈ›ii acoperÄƒ lipsurile de conformitate identificate[15] È™i asigurÄƒ cÄƒ datele personale sunt gestionate transparent È™i È™terse la termen[16]. Vom folosi scripturi Python (cron jobs locale), SQLite È™i fiÈ™iere JSON/CSV pentru a realiza aceste cerinÈ›e gratuit.
2.1 RetenÈ›ie AutomatÄƒ a Datelor (Auto-Delete)
â€¢	È˜tergere fiÈ™iere dupÄƒ 30 zile: Vom implementa o politicÄƒ de retenÈ›ie conform recomandÄƒrilor â€“ fiÈ™ierele Ã®ncÄƒrcate de clienÈ›i È™i rezultatele traducerii vor fi pÄƒstrate maxim 30 de zile pe server, dupÄƒ care se È™terg automat[17]. Acest interval acoperÄƒ nevoile uzuale (clientul poate descÄƒrca traducerea sau cere rectificÄƒri Ã®ntr-o lunÄƒ) È™i limiteazÄƒ expunerea datelor pe termen lung. Implementare: un cron job zilnic (sau folosind un scheduler Python) va parcurge directorul uploads/ È™i alte foldere relevante (ex. processed/ pentru traduceri livrate) È™i va È™terge fiÈ™ierele mai vechi de 30 de zile (comparÃ¢nd timestamp-ul fiÈ™ierului cu data curentÄƒ). Vom putea folosi o bibliotecÄƒ precum schedule sau APScheduler (free) Ã®n modul daemon al aplicaÈ›iei, sau alternativ un script separat cleanup.py pus Ã®n crontab al serverului, care ruleazÄƒ zilnic noaptea. Orice fiÈ™ier È™ters va fi notat Ã®n log-ul de audit cu data È™i identificator (pentru evidenÈ›Äƒ).
â€¢	È˜tergere/anonomizare metadata dupÄƒ 365 zile: Conform GDPR, datele personale din sistem (metadate precum informaÈ›ii despre comenzi, email-uri de contact, istoricul traducerilor) vor fi pÄƒstrate cel mult 1 an dupÄƒ care eliminate sau anonimizate[17]. Implementare: Ã®n SQLite, vom marca intrÄƒrile mai vechi de 365 zile pentru È™tergere. De exemplu, tabele precum orders, payments, logs vor fi curÄƒÈ›ate de toate rÃ¢ndurile mai vechi de un an. Pentru a nu pierde eventuale statistici agregate, se poate Ã®n loc de È™tergere directÄƒ sÄƒ se anonimizeze unele cÃ¢mpuri (ex: Ã®nlocuire email cu hash sau â€œDELETEDâ€) astfel Ã®ncÃ¢t datele sÄƒ nu mai fie personale, dar sÄƒ poatÄƒ fi folosite la raportÄƒri generale. TotuÈ™i, conform cerinÈ›ei ne vom concentra pe È™tergere completÄƒ. Un script similar (cron zilnic sau lunar) se va ocupa de acest proces pe DB.
â€¢	Soft delete È™i backup local: Vom introduce conceptul de â€soft deleteâ€ pentru un interval scurt, pentru a permite eventuale recuperÄƒri dacÄƒ È™tergerea s-a fÄƒcut din greÈ™ealÄƒ. Concret, Ã®nainte de È™tergerea definitivÄƒ, datele vor fi backup-ate local pe termen scurt. De exemplu, fiÈ™ierele ce urmeazÄƒ a fi È™terse pot fi mutate Ã®ntr-un director backup_deleted/ (sau arhivate .zip) cu un timestamp, È™i pÄƒstrate acolo Ã®ncÄƒ ~7 zile Ã®nainte de È™tergerea finalÄƒ. Similar, Ã®nainte de a È™terge rÃ¢nduri din SQLite, le putem copia Ã®ntr-o tabelÄƒ de backup (sau exporta Ã®ntr-un fiÈ™ier CSV/JSON) stocatÄƒ local pentru o perioadÄƒ scurtÄƒ. Acest mecanism asigurÄƒ posibilitatea de restaurare a datelor È™terse recent dacÄƒ, de exemplu, un client solicitÄƒ recuperarea din greÈ™ealÄƒ. DupÄƒ perioada de graÈ›ie (ex. 7 zile), backup-urile respective sunt È™i ele È™terse automat. Toate aceste acÈ›iuni vor fi consemnate Ã®n audit log.
â€¢	Audit trail È™tergeri: Fiecare execuÈ›ie de retenÈ›ie va fi logatÄƒ: vom crea un fiÈ™ier de audit (sau adÄƒuga Ã®ntr-un JSON log comun) evenimente de tip "DataRetentionDeletion" conÈ›inÃ¢nd ce s-a È™ters (ex: "user X â€“ È™ters fiÈ™ier Y uploadat la data Z" sau "È™ters Ã®nregistrÄƒri comenzi din <2024") È™i timestamp-ul. Acest audit trail completeazÄƒ cerinÈ›a de a pÄƒstra evidenÈ›a acÈ›iunilor asupra datelor personale[18].
â€¢	Configurabil È™i extensibil: Valorile de retenÈ›ie (30 zile, 365 zile) vor fi puse Ã®n fiÈ™ierul de configurare YAML, pentru a le putea modifica uÈ™or Ã®n viitor (de exemplu, dacÄƒ se schimbÄƒ politica de companie sau cerinÈ›ele legale). Sistemul de cleanup poate fi extins sÄƒ È™teargÄƒ È™i alte tipuri de date temporare (ex: token-uri expirate, log-uri vechi mai mult de X timp, etc., deÈ™i log-urile pot fi pÄƒstrate mai mult Ã®n scop de securitate).
ImplementÃ¢nd retenÈ›ia automatÄƒ, ne asigurÄƒm cÄƒ nu stocÄƒm date personale mai mult decÃ¢t e necesar, Ã®ndeplinind cerinÈ›ele GDPR de minimizare a perioadei de stocare. Acest lucru evitÄƒ È™i Ã®ncÄƒrcarea inutilÄƒ a serverului cu fiÈ™iere vechi.
2.2 Portal Client DSAR (Export/È˜tergere Date)
â€¢	InterfaÈ›Äƒ self-service: Vom crea un portal web securizat unde clienÈ›ii Ã®È™i pot exercita drepturile GDPR: sÄƒ descarce toate datele lor stocate sau sÄƒ solicite È™tergerea completÄƒ a datelor. Conform specificaÈ›iei, vom implementa acest portal local, ca parte a site-ului (fÄƒrÄƒ servicii externe). Ãn pagina principalÄƒ sau Ã®ntr-o secÈ›iune dedicatÄƒ (ex: "GDPR/Data Request"), utilizatorul poate alege: ExportÄƒ datele mele sau È˜terge datele mele.
â€¢	Identificare prin email: Pentru a identifica datele utilizatorului, vom folosi adresa de email (pe care clientul a furnizat-o la plasarea comenzii/traducerii). Formularul DSAR va cere utilizatorului sÄƒ introducÄƒ emailul folosit Ã®n sistem. Deoarece nu avem conturi cu autentificare, vom verifica identitatea printr-un cod de confirmare trimis pe email Ã®nainte de a livra datele sau a le È™terge, prevenind ca cineva sÄƒ Ã®ncerce accesul pe baza emailului altcuiva. Acesta este un proces simplu de verificare prin email, conform cerinÈ›ei[17].
â€¢	Flux export date (Download ZIP): DacÄƒ utilizatorul alege exportul datelor:
â€¢	DupÄƒ introducerea email-ului, serverul genereazÄƒ un token unic (un UUID) asociat cererii È™i Ã®l salveazÄƒ Ã®n SQLite (tabel dsar_requests cu email, token, tip cerere, expiraÈ›ie).
â€¢	Se trimite un email cÄƒtre adresa respectivÄƒ conÈ›inÃ¢nd un link securizat de download, de forma https://siteul-meu/DSAR/export?token=<UUID>. Acest email va fi expediat folosind un SMTP gratuit â€“ putem folosi contul propriu Gmail prin smtplib (cu autentificare pe baza unui app password) sau un server SMTP local. Implementarea trimiterii emailului se face Ã®n modul asincron (se poate folosi thread separat sau Celery task, dacÄƒ disponibil, pentru a nu bloca rÄƒspunsul).
â€¢	CÃ¢nd userul primeÈ™te emailul È™i dÄƒ click pe link, serverul valideazÄƒ token-ul: cautÄƒ token-ul Ã®n DB, verificÄƒ dacÄƒ este valid È™i neexpirat (setÄƒm o valabilitate de ~24 ore).
â€¢	DacÄƒ valid, sistemul pregÄƒteÈ™te toate datele utilizatorului Ã®ntr-un pachet ZIP. Aceasta include: toate fiÈ™ierele Ã®ncÄƒrcate de utilizator (dacÄƒ mai existÄƒ Ã®n uploads/ sub 30 zile), traducerile rezultate (dacÄƒ existÄƒ fiÈ™iere de ieÈ™ire stocate), È™i un fiÈ™ier .json sau .csv cu metadatele â€“ de ex. conÈ›inutul tuturor Ã®nregistrÄƒrilor din SQLite legate de email-ul lui (comenzi, plÄƒÈ›i, log-uri relevante). Vom realiza exportul prin interogÄƒri SQLite pe tabele (SELECT * FROM orders/payments where email=X) È™i scrierea rezultatelor Ã®ntr-un format tabular sau JSON uÈ™or de Ã®nÈ›eles.
â€¢	Folosim Python zipfile pentru a adÄƒuga toate aceste date Ã®n arhivÄƒ. De exemplu, data_export_<email>_<date>.zip va conÈ›ine: orders.csv, translations_list.csv, personal_data.json È™i eventual subfoldere files/ cu documentele originale È™i traducerile (dacÄƒ disponibile).
â€¢	Apoi livrÄƒm acest ZIP fie direct ca rÄƒspuns la download (cu send_file Flask, application/zip), fie oferim un link de download Ã®n paginÄƒ. DupÄƒ download, din motive de securitate, putem invalida imediat token-ul (È™i eventual È™terge arhiva temporarÄƒ dacÄƒ am salvat-o pe disc). Astfel, datele ajung la user Ã®n mod securizat.
â€¢	Flux È™tergere date: DacÄƒ utilizatorul solicitÄƒ È™tergerea:
â€¢	Procedura de autentificare este similarÄƒ: introduce email, primeÈ™te un link de confirmare ...?token=XYZ pentru È™tergere.
â€¢	CÃ¢nd acceseazÄƒ link-ul, token-ul e verificat. Pentru È™tergere, vom cere o confirmare suplimentarÄƒ (ex: o paginÄƒ "EÈ™ti sigur cÄƒ vrei sÄƒ È™tergi permanent toate datele?" cu buton "ConfirmÄƒ È™tergerea"), ca mÄƒsurÄƒ de siguranÈ›Äƒ Ã®mpotriva click-urilor accidentale din email.
â€¢	La confirmare, serverul va identifica toate datele asociate acelui email Ã®n sistem:
o	FiÈ™iere Ã®ncÄƒrcate Ã®n uploads/ (È™i eventual traduceri Ã®n processed/): le va È™terge imediat (folosind aceleaÈ™i funcÈ›ii ca la retenÈ›ia automatÄƒ, dar forÈ›at acum). Ãnainte de È™tergere definitivÄƒ, putem aplica È™i aici soft delete â€“ de exemplu mutÄƒm fiÈ™ierele Ã®ntr-un backup special (criptat eventual) pentru o perioadÄƒ scurtÄƒ, Ã®n caz de disputÄƒ, dar oficial faÈ›Äƒ de client le considerÄƒm È™terse.
o	ÃnregistrÄƒri Ã®n baza de date (comenzi, plÄƒÈ›i, memorie traduceri, preferinÈ›e, log-uri ce conÈ›in emailul): le va È™terge sau anonimiza. Vom rula comenzi DELETE pe tabelele relevante cu condiÈ›ia email = client. Cheile strÄƒine È™i integritatea referenÈ›ialÄƒ trebuie avute Ã®n vedere; dacÄƒ existÄƒ, se vor È™terge Ã®n ordinea corectÄƒ sau cu CASCADE. Alternativ, dacÄƒ dorim pÄƒstrarea unor statistici anonime (ex: numÄƒr de cuvinte traduse), putem Ã®n loc sÄƒ È™tergem intrÄƒrile din orders sÄƒ le anonimizÄƒm (email devine "deleted_user_123"), Ã®nsÄƒ conform cerinÈ›ei vom realiza È™tergere completÄƒ.
â€¢	DupÄƒ È™tergere, vom trimite un email automat de confirmare cÄƒtre client: un mesaj cÄƒ "Toate datele asociate adresei dvs. au fost È™terse definitiv la data... DacÄƒ aveÈ›i alte solicitÄƒri bla bla".
â€¢	Ãn log-ul de audit, Ã®nregistrÄƒm acÈ›iunea de È™tergere: cine (email) a fost È™ters, la ce orÄƒ, È™i ce categorii de date au fost eliminate.
â€¢	Securitate È™i restricÈ›ii: Link-urile de confirmare au un token unic dificil de ghicit È™i sunt valabile limitat Ã®n timp. OdatÄƒ folosite sau expirate, ele sunt È™terse din DB. De asemenea, vom implementa o limitare: dacÄƒ cineva introduce un email care nu existÄƒ Ã®n sistem, vom afiÈ™a acelaÈ™i mesaj generic ("DacÄƒ adresa existÄƒ, veÈ›i primi un email..."), ca sÄƒ nu divulgÄƒm informaÈ›ia cÄƒ un anumit email e sau nu Ã®n baza noastrÄƒ (prin asta evitÄƒm un potenÈ›ial leak de existenÈ›Äƒ a datelor). Pentru emailul de trimitere vom folosi un cont propriu (SMTP Gmail configurat Ã®n config.yaml cu user/parolÄƒ sau un SMTP local dacÄƒ disponibil) â€“ aceastÄƒ soluÈ›ie este gratuitÄƒ. SMTP-ul trebuie configurat cu TLS (smtplib se ocupÄƒ de asta) pentru confidenÈ›ialitatea mesajelor.
â€¢	Implementare modularÄƒ: Vom crea probabil un modul dsar_service.py care conÈ›ine funcÈ›ii: send_export_email(email), send_delete_email(email), perform_export(token) È™i perform_delete(token). Rutele Flask /request-export È™i /request-delete vor primi formularul iniÈ›ial, iar rutele /export?token= È™i /delete?token= vor realiza acÈ›iunile finale. Acest design separÄƒ clar logica È™i permite testare uÈ™oarÄƒ.
Cu acest portal DSAR, respectÄƒm cerinÈ›ele GDPR de acces È™i È™tergere la cerere a datelor[16], oferind utilizatorilor control È™i transparenÈ›Äƒ totalÄƒ. Totul este self-hosted È™i custom, fÄƒrÄƒ costuri suplimentare, dar oferind o experienÈ›Äƒ profesionalÄƒ (email automat, arhivÄƒ completÄƒ de date).
2.3 Audit Logging Ã®n FiÈ™iere (Traceabilitate)
â€¢	Jurnalizare Ã®n format JSON: Vom introduce un sistem de logare detaliatÄƒ a evenimentelor aplicaÈ›iei, pentru a avea un audit trail complet al acÈ›iunilor (cum solicitÄƒ GDPR È™i bunele practici de securitate)[15]. Log-urile vor fi stocate Ã®n fiÈ™iere pe disc (directorul logs/[19]) È™i vor fi Ã®n format JSON pentru a facilita procesarea ulterioarÄƒ. Fiecare eveniment va fi reprezentat ca un obiect JSON pe o linie (JSON Lines), conÈ›inÃ¢nd cÃ¢mpuri precum timestamp, tip eveniment, detalii relevante (user, IP, id comanda etc.). Acest format permite cu uÈ™urinÈ›Äƒ sÄƒ fie filtrat sau transformat ulterior (ex: importat Ã®ntr-un pandas DataFrame pentru analizÄƒ).
â€¢	Evenimente logate: Vom loga automat urmÄƒtoarele categorii de acÈ›iuni:
â€¢	Securitate: orice autentificare webhook eÈ™uatÄƒ, orice block de rate-limit sau ban, Ã®ncercÄƒri de upload respinse, accesÄƒri neautorizate (de ex. cineva Ã®ncearcÄƒ un URL inexistent).
â€¢	TranzacÈ›ii È™i plÄƒÈ›i: recepÈ›ie webhook Stripe valid (cu ID tranzacÈ›ie), plÄƒÈ›i confirmate, erori de platÄƒ.
â€¢	AcÈ›iuni utilizator: upload fiÈ™ier (cu meta ex: nume, tip), generare preview, realizare traducere finalÄƒ, descÄƒrcare fiÈ™ier.
â€¢	DSAR: cerere export iniÈ›iatÄƒ, export livrat, cerere È™tergere iniÈ›iatÄƒ, È™tergere efectuatÄƒ (incluzÃ¢nd ce date s-au È™ters).
â€¢	Sistem: È™tergeri automate (cu numÄƒr de fiÈ™iere È™terse), backup realizat, pornire/oprire servicii, erori neprevÄƒzute (traceback-uri).
Practic, orice acÈ›iune care modificÄƒ date sau este relevantÄƒ pentru audit va genera o intrare log. Acest lucru Ã®ndeplineÈ™te cerinÈ›a de audit logging complet pentru fiecare acÈ›iune[18].
â€¢	Rotirea È™i comprimarea log-urilor: Pentru a evita ca fiÈ™ierele de log sÄƒ devinÄƒ foarte mari È™i pentru a organiza istoricul, vom implementa un mecanism de rotating logs. Vom crea fiÈ™iere separate fie pe categorii, fie pe interval de timp:
â€¢	De exemplu, un fiÈ™ier logs/audit_2025-08-15.json pentru activitatea zilei respective, care a doua zi se Ã®nchide È™i se porneÈ™te unul nou. Sau putem folosi un singur log audit È™i sÄƒ-l rotim cÃ¢nd depÄƒÈ™eÈ™te o dimensiune (ex: 10 MB) sau zilnic la miezul nopÈ›ii. Biblioteca logging din Python are un RotatingFileHandler È™i TimedRotatingFileHandler care pot fi folosite pentru uÈ™urinÈ›Äƒ, dar putem È™i manual.
â€¢	DupÄƒ rotire, fiÈ™ierele de log vechi vor fi comprimat automat (e.g. se poate configura ca fiÈ™ierul Ã®nchis sÄƒ fie arhivat .gz sau .zip). Astfel, audit_2025-08-14.json devine audit_2025-08-14.json.gz pentru a economisi spaÈ›iu.
â€¢	Vom pÄƒstra log-urile comprimate local atÃ¢ta timp cÃ¢t e necesar (poate 1-2 ani, sau conform politicii interne) deoarece log-urile nu conÈ›in neapÄƒrat date personale (dacÄƒ conÈ›in emailuri, totuÈ™i intrÄƒ sub GDPR È™i atunci reÈ›inem max 1 an È™i pentru ele). Se poate aplica È™i pe ele aceeaÈ™i curÄƒÈ›are dupÄƒ 365 zile, eventual.
â€¢	Export È™i analizÄƒ log-uri: Vom furniza scripturi utilitare pentru a lucra cu aceste log-uri:
â€¢	Un script Python (ex: tools/logs_to_csv.py) care citeÈ™te fiÈ™ierele JSON È™i produce un CSV agregat (sau rapoarte sumare). Acesta ajutÄƒ la audit extern sau la analizÄƒ managerialÄƒ.
â€¢	Un alt script tools/search_logs.py care permite filtrarea logurilor dupÄƒ criterii â€“ ex: dupÄƒ email-ul userului, dupÄƒ tip eveniment, datÄƒ etc. Acesta poate parcurge fiÈ™ierele (inclusiv pe cele .gz) È™i afiÈ™a intrÄƒrile relevante. Acest tool uÈ™ureazÄƒ rÄƒspunsul la Ã®ntrebÄƒri de tip: "sÄƒ gÄƒsim toate acÈ›iunile legate de user X Ã®n ultimele 6 luni" sau "toate upload-urile respinse ca tip invalid".
â€¢	De asemenea, includem un script de backup a log-urilor: lunar, toate logurile lunii precedente pot fi arhivate Ã®ntr-un logs_archive_2025-08.tar.gz È™i mutate Ã®ntr-un director separat sau pe un storage extern (dacÄƒ se configureazÄƒ unul local). Acest proces poate fi integrat Ã®n jobul de retenÈ›ie sau rulat manual.
â€¢	Implementare Ã®n cod: Vom configura logger-ul global al aplicaÈ›iei Flask sÄƒ foloseascÄƒ un custom formatter pentru JSON (sau vom loga manual evenimentele critice). E relativ uÈ™or sÄƒ facem un dict È™i sÄƒ-l serializÄƒm cu json.dumps() Ã®n fiÈ™ier. Putem crea un helper audit_log(event_type, details_dict) care sÄƒ ataÈ™eze timestamp automat È™i sÄƒ scrie Ã®n fiÈ™ierul curent. Pentru logarea request-urilor, Flask oferÄƒ after-request handlers â€“ putem intercepta rÄƒspunsurile 4xx/5xx sÄƒ le logÄƒm. ÃnsÄƒ majoritatea evenimentelor le vom loga direct Ã®n locurile din cod unde se Ã®ntÃ¢mplÄƒ (ex: dupÄƒ ce È™tergem datele cuiva, apelÄƒm audit_log("DSAR_DELETE", {"email": user_email, "records_deleted": X, "files_deleted": Y})).
Prin acest sistem de logging, obÈ›inem transparenÈ›Äƒ totalÄƒ È™i posibilitatea de audit a sistemului. Ãn caz de incidente (de ex. o plÃ¢ngere GDPR), putem demonstra exact cine È™i cÃ¢nd a accesat sau È™ters date[20]. De asemenea, log-urile ajutÄƒ la debugging È™i la monitorizarea sÄƒnÄƒtÄƒÈ›ii aplicaÈ›iei Ã®n exploatare.
ğŸ§  Componenta 3: ADN #1 â€“ Context Specializat (AI Adaptation)
Componenta ADN #1 introduce inteligenÈ›a contextualÄƒ Ã®n traduceri â€“ sistemul va detecta automat domeniul textului È™i va adapta traducerea (prin prompt-uri, glosare locale È™i post-procesare) pentru a menÈ›ine acurateÈ›ea terminologicÄƒ. De asemenea, vom implementa funcÈ›ionalitÄƒÈ›i conexe: pricing diferenÈ›iat Ã®n funcÈ›ie de context (domeniile specializate au cost uÈ™or mai ridicat) È™i memorie client (Ã®nvÄƒÈ›area preferinÈ›elor È™i reutilizarea traducerilor anterioare). Scopul este creÈ™terea calitÄƒÈ›ii È™i oferirea de opÈ›iuni premium (ex. pachete pe industrii) â€“ idee aliniatÄƒ cu Industry Packs È™i Smart Pricing din planul enterprise[3][21]. Toate soluÈ›iile folosite sunt locale (algorithmic, configurÄƒri) fÄƒrÄƒ API-uri plÄƒtite suplimentare, folosind motoarele existente (DeepL/Google) Ã®ntr-un mod optimizat.
3.1 Detectare AutomatÄƒ a Contextului (Algoritm Bag-of-Words)
â€¢	Domenii suportate: Vom defini o listÄƒ de ~8 domenii posibile pentru contextul documentului, conform celor discutate anterior[22][23]. De exemplu: General, Tehnic/Ingineresc, IT/Informatica, Juridic, Medical, Business/Economic, Sportiv, Academic etc. Aceste domenii acoperÄƒ categoriile majore identificate ca relevante pentru traduceri specializate. Lista exactÄƒ È™i denumirile pot fi ajustate; Ã®n knowledge base s-au propus liste extinse (MatematicÄƒ & StatisticÄƒ, InformaticÄƒ & IT, Legal, Medical, Marketing, etc.) pe care ne vom baza[23].
â€¢	DicÈ›ionare de cuvinte-cheie: Pentru fiecare domeniu vom pregÄƒti un dicÈ›ionar local de termeni reprezentativi. Acestea pot fi fiÈ™iere JSON separate (ex: keywords_medical.json, keywords_legal.json, ...) sau un singur fiÈ™ier YAML care conÈ›ine sub-chei pe domenii cu lista de cuvinte asociate. Termenii vor include jargon specific domeniului respectiv. De pildÄƒ, pentru medical: termeni precum â€œclinic, pacient, terapie, simptom, diagnostic, mg, ml, etc.â€; pentru juridic: â€œcontract, lege, articol, alin., instanÈ›Äƒ, obligaÈ›ie, testament, etc.â€; pentru IT: â€œalgoritm, server, cod sursÄƒ, runtime, AI, reÈ›eaâ€ etc. Putem compune aceste liste manual È™i le putem extinde Ã®n timp. Acest approach bag-of-words simplu ne oferÄƒ un indicator al domeniului pe baza frecvenÈ›ei cuvintelor specifice.
â€¢	Analiza primelor N cuvinte: Vom rula algoritmul de detecÈ›ie pe primele ~500 de cuvinte ale textului (sau primele 1-2 pagini) â€“ premisÄƒ: primele paragrafe sunt de obicei suficiente pentru a deduce contextul general. Limitarea la N cuvinte reduce costul computaÈ›ional È™i evitÄƒ bias-ul dat de porÈ›iuni de text care poate nu sunt relevante (ex. anexe). Pentru extragerea textului deja existÄƒ componenta de procesare document (OCR, parser PDF/DOCX)[13]; vom folosi rezultatul acela (text brut sau partial) ca input.
â€¢	Tokenizare È™i curÄƒÈ›are: Folosim Python NLTK (gratuit) pentru a tokeniza textul È™i eventual a elimina stopwords (cuvinte foarte comune gen â€œÈ™i, de, laâ€ care nu ajutÄƒ la identificare). NLTK are liste de stopwords pentru limba romÃ¢nÄƒ È™i englezÄƒ â€“ le vom folosi pentru a filtra ruÈ™ii. RulÄƒm totul lower-case pentru a uniformiza. Putem, de asemenea, sÄƒ extragem radicalul cuvintelor (stemming) pentru a prinde variaÈ›ii (ex: "legal"/"legale"/"legislaÈ›ie" â€“ un stemmer romÃ¢nesc sau pur È™i simplu includem variaÈ›ii Ã®n liste).
â€¢	Scor de frecvenÈ›Äƒ: Pentru fiecare domeniu calculÄƒm un scor bazat pe frecvenÈ›a cuvintelor-cheie din lista sa ce apar Ã®n text. De exemplu, numÄƒrÄƒm de cÃ¢te ori apar cuvintele din keywords_medical Ã®n text, aceasta va fi scorul pentru medical. Putem normaliza scorul la lungimea textului (dar cum vom compara scorurile Ã®ntre domenii, lungimea e aceeaÈ™i oricum pentru toÈ›i, deci nu e necesarÄƒ normalizare complicatÄƒ). Putem totuÈ™i sÄƒ acordÄƒm ponderi diferite unor termeni: de exemplu, un cuvÃ¢nt foarte specific (ex: â€œHabeas corpusâ€ pentru juridic, sau â€œappendicitisâ€ pentru medical) ar putea conta drept +5 puncte, pe cÃ¢nd unul mai comun (â€œdoctorâ€) +1. IniÈ›ial vom simplifica luÃ¢nd doar frecvenÈ›a brutÄƒ.
â€¢	Determinarea domeniului predominant: ComparÄƒm scorurile tuturor domeniilor. DacÄƒ un domeniu are un scor semnificativ mai mare decÃ¢t celelalte, Ã®l alegem ca context detectat. Trebuie stabilit È™i un prag de Ã®ncredere. De exemplu, dacÄƒ scorul maxim reprezintÄƒ <70% din totalul cuvintelor relevante gÄƒsite sau diferenÈ›a faÈ›Äƒ de al doilea scor e micÄƒ, putem clasa documentul ca "General" (fÄƒrÄƒ un context special clar)[24]. Pragul de 70% e empiric â€“ putem ajusta dupÄƒ teste. SituaÈ›ii:
â€¢	DacÄƒ textul conÈ›ine mulÈ›i termeni tehnici amestecaÈ›i (ex: un raport È™tiinÈ›ific poate avea atÃ¢t termeni tehnici cÃ¢t È™i juridici Ã®n preambul), algoritmul poate detecta 2 scoruri apropiate; atunci default "General" e mai sigur decÃ¢t o alegere greÈ™itÄƒ.
â€¢	DacÄƒ niciun domeniu nu are vreun hit (text foarte general), clar va rezulta "General".
â€¢	DacÄƒ un domeniu dominÄƒ (ex: 10 termeni medicali vs 0 din altele), luÄƒm "Medical" cu Ã®ncredere ridicatÄƒ.
â€¢	Fallback la selecÈ›ia utilizatorului: NotÄƒm cÄƒ Ã®n interfaÈ›Äƒ vom oferi oricum utilizatorului un dropdown de selecÈ›ie a domeniului (ex: "Context Document: General / Juridic / Medical / ...")[22]. Detectarea automatÄƒ va fi folositÄƒ iniÈ›ial pentru a pre-selecta domeniul Ã®n dropdown sau pentru a sugera utilizatorului contextul. Clientul are opÈ›iunea sÄƒ schimbe dacÄƒ detectarea nu a nimerit (ex: Ã®l lÄƒsÄƒm sÄƒ selecteze manual alt domeniu). DacÄƒ utilizatorul schimbÄƒ manual, vom folosi alegerea sa È™i putem actualiza È™i modul nostru de Ã®nvÄƒÈ›are (ex: dacÄƒ sistemul a detectat "General" dar user a selectat "Legal", putem re-evalua listele sau pur È™i simplu memora preferinÈ›a pentru acel user â€“ vezi Memory Client).
â€¢	Integrare cu pipeline-ul: OdatÄƒ stabilit contextul (fie auto, fie manual de la client), Ã®l vom transmite mai departe modulului de traducere (3.2) È™i modulului de calcul cost (3.3). De exemplu, salvÄƒm contextul selectat Ã®n obiectul de comandÄƒ curent (sau Ã®ntr-o variabilÄƒ de sesiune) pentru a fi folosit la traducere. TotodatÄƒ Ã®l stocÄƒm Ã®n DB (tabel orders.context) pentru analytics ulterioare (sÄƒ vedem ce pondere de documente sunt pe domenii specializate).
Acest algoritm bag-of-words este simplu dar eficient pentru a oferi o detecÈ›ie rapidÄƒ a domeniului fÄƒrÄƒ modele ML complexe. Fiind complet local È™i personalizabil (putem Ã®mbunÄƒtÄƒÈ›i listele de cuvinte Ã®n timp), asigurÄƒ o adaptare a traducerii la contextul potrivit Ã®n majoritatea cazurilor. Astfel, sistemul nostru poate oferi traduceri mai precise pentru termeni tehnici È™i stil adecvat fiecÄƒrui domeniu (ex: ton formal juridic vs colocvial Ã®n sport) â€“ beneficii subliniate È™i Ã®n planificarea iniÈ›ialÄƒ[25].
3.2 Adaptarea Motorului de Traducere cu Prompting (DeepL/Google)
â€¢	Configurare context specializat: Vom crea o configuraÈ›ie centralÄƒ (de exemplu un dict CONTEXT_SETTINGS Ã®n cod sau un fiÈ™ier YAML) care mapeazÄƒ fiecare domeniu la anumite parametri de traducere È™i acÈ›iuni specifice. Aceasta a fost deja schiÈ›atÄƒ Ã®n knowledge base ca un snippet exemplu[26]. De exemplu:
â€¢	CONTEXT_SETTINGS['juridic'] = { "deepl_formality": "more", "glossary": "legal_ro_en.txt", "prompt": "Tradu textul Ã®n stil juridic, cu limbaj formal È™i termeni legali preciÈ™i." }
â€¢	CONTEXT_SETTINGS['medical'] = { "deepl_formality": "more", "prompt": "Traducere context medical - pÄƒstreazÄƒ terminologia anatomicÄƒ exactÄƒ È™i unitÄƒÈ›ile de mÄƒsurÄƒ.", "terminology_enforcement": true }
â€¢	CONTEXT_SETTINGS['informatica'] = { "deepl_formality": "less", "code_preservation": true, "prompt": "Translate technical text preserving code and symbols unchanged." }
etc. Aceste setÄƒri vor fi folosite atÃ¢t Ã®nainte de traducere (prompting, parametri API) cÃ¢t È™i dupÄƒ (post-procesare regex).
â€¢	Pre-procesare (context hints): Ãnainte de a trimite textul la API-ul de traducere (DeepL sau Google Translate), aplicÄƒm transformÄƒri uÈ™oare pentru a ghida traducÄƒtorul:
â€¢	Formatare/Tagging special: DacÄƒ domeniul implicÄƒ pÄƒrÈ›i care nu trebuie traduse, le vom marca. Exemplu: pentru domeniul IT, detectÄƒm bucÄƒÈ›i de cod sursÄƒ sau comenzi (poate cu regex pentru segmente Ã®n backticks, sau secvenÈ›e ce aratÄƒ a cod) È™i le Ã®nlocuim temporar cu un token sau le Ã®ncadrÄƒm Ã®n tag-uri <code>...</code>. DacÄƒ folosim DeepL API cu tag_handling="xml" È™i specificÄƒm cÄƒ tag-ul <code> e non-translatable, DeepL va lÄƒsa conÈ›inutul neschimbat[27]. Asta asigurÄƒ cÄƒ int main() rÄƒmÃ¢ne int main(), nu devine principal.
â€¢	Similar, pentru matematicÄƒ, am putea Ã®ncadra formulele Ã®n <formula>...</formula> È™i marca tag-ul ca netraductibil. De exemplu, expresii cu multe cifre, simboluri speciale sau LaTeX.
â€¢	AdÄƒugare prompt context Ã®n text: DacÄƒ API-ul nu suportÄƒ parametri direcÈ›i de ton/hints (Google Translate standard nu are, DeepL are formality limitat), putem adÄƒuga manual un scurt prompt Ã®n text. Strategie: concatenÄƒm la Ã®nceputul textului original o frazÄƒ de context Ã®ntre paranteze pÄƒtrate sau alt marker care apoi Ã®l vom elimina. Exemplu: pentru domeniul juridic, prefaÈ›Äƒm textul cu [Context: Document juridic, limbaj formal] sau chiar Ã®ntr-o variantÄƒ englezÄƒ dacÄƒ traducem spre englezÄƒ. TraducÄƒtorul neuronal poate astfel adapta stilul. Important: dupÄƒ primirea traducerii, vom elimina sau ajusta partea de prompt dacÄƒ a fost tradusÄƒ. AceastÄƒ metodÄƒ e empiricÄƒ È™i s-ar putea ca motorul de traducere sÄƒ traducÄƒ promptul ca atare; vom experimenta. Ãn cazul DeepL, putem folosi parametri formality direct pentru limbile suportate (ex: Ã®n API, formality: "formal").
â€¢	Glossar (cÃ¢nd posibil): DacÄƒ avem un mic glosar de termeni specifici domeniului (ex: Legal â€“ "contract"->"contract", "procuror"->"prosecutor" etc.), pentru DeepL Pro se pot crea glosare custom. ÃnsÄƒ presupunÃ¢nd cÄƒ folosim plan free sau Google, vom implementa glosarul tot manual: Ã®nainte de traducere, putem Ã®nlocui termenii sursÄƒ care nu vrem traduÈ™i cu un placeholder (ex: "#TERM1#"), È™i dupÄƒ traducere punem Ã®napoi termenul original sau traducerea doritÄƒ. De ex., dacÄƒ vrem sÄƒ ne asigurÄƒm cÄƒ "EU" ca abreviere de Uniunea EuropeanÄƒ nu se traduce "SUA" din greÈ™ealÄƒ, o putem Ã®nlocui cu "#EU#". Asta echivaleazÄƒ cu a da hints motorului sÄƒ nu traducÄƒ anumite entitÄƒÈ›i.
â€¢	Trimitere cÄƒtre API: OdatÄƒ pre-procesat textul, Ã®l vom transmite cÄƒtre DeepL (dacÄƒ cheia API este disponibilÄƒ) sau Google Translate API (dacÄƒ are credite gratuite). Vom folosi preferabil DeepL ca prim motor (calitate mai bunÄƒ), È™i Google ca fallback[28]. Implementarea actualÄƒ are deja integrarea cu DeepL Pro È™i Google Translate Ã®n translation_service.py[29] â€“ vom extinde acea logicÄƒ: adÄƒugÄƒm parametrii contextuali. Ãn cazul DeepL, putem seta parametru formality conform CONTEXT_SETTINGS[domeniu]['deepl_formality']. Pentru Google, nu existÄƒ parametri de formalitate, dar traducÃ¢nd Ã®n RO putem eventual seta modelul dacÄƒ ar exista vreo opÈ›iune (nu prea Ã®n free, decÃ¢t default). Oricum, trimitem textul (cu eventualul prompt inclus).
â€¢	Trebuie menÈ›ionat cÄƒ folosirea acestor API nu implicÄƒ costuri dacÄƒ rÄƒmÃ¢nem Ã®n limita planului gratuit: DeepL are un free tier (max 500k caractere/lunÄƒ) care ne poate ajunge la Ã®nceput, iar Google Translate are ~500$ credit la activare. Deci Ã®n contextul "fÄƒrÄƒ costuri", putem fie limita volumul, fie folosi aceste planuri gratuite. O alternativÄƒ complet open-source ar fi folosirea unui model de traducere open (ex MarianNMT sau Argos Translate offline), dar calitatea ar scÄƒdea. Ca atare, vom continua cu DeepL/Google asumÃ¢nd utilizarea judicioasÄƒ a planurilor gratuite.
â€¢	Post-procesare traducere: DupÄƒ obÈ›inerea textului tradus de la API, vom aplica post-procesÄƒri pentru terminologie:
â€¢	Ãnlocuire placeholder-e originale: Orice secvenÈ›e protejate Ã®n pre-procesare (ex: cod Ã®n <code>, formule, entitÄƒÈ›i "#TERM#") le vom restaura acum Ã®n textul tradus. De obicei, DeepL respectÄƒ tag-urile È™i ni le returneazÄƒ intacte, deci e simplu: scoatem tag-urile <code> È™i pÄƒstrÄƒm conÈ›inutul. Pentru placeholders gen "#EU#", cÄƒutÄƒm acel token Ã®n string-ul tradus È™i punem "UE" (sau ce decidem conform glosar).
â€¢	Regex pentru nomenclaturÄƒ: Putem rula expresii regulate pentru a corecta formatele specifice: de exemplu, Ã®n textul tradus, asigurÄƒ-te cÄƒ numeralele È™i unitÄƒÈ›ile au fost pÄƒstrate corect (ex: "12mm" nu trebuie sÄƒ devinÄƒ "12 mm" sau "12 milimetri" dacÄƒ nu dorim asta; pentru un document tehnic poate vrem exact). Sau dacÄƒ È™tim cÄƒ Ã®n original apar coduri (ex: "Art. 123") È™i traducerea le-a modificat (de exemplu a schimbat ordinea cuvintelor), le putem reformat dupÄƒ modelul original. Aceste ajustÄƒri pot fi custom per domeniu.
â€¢	Enforce terminologie preferatÄƒ: DacÄƒ avem un glosar de termeni specifici domeniului, putem parcurge textul tradus È™i Ã®nlocui termenii traducerii cu varianta preferatÄƒ. Exemplu: Ã®n domeniul medical, dacÄƒ È™tim cÄƒ "heart" ar trebui tradus mereu "inimÄƒ" È™i nu "cord", putem cÄƒuta cuvÃ¢ntul "cord" È™i dacÄƒ contextul e medical, Ã®l Ã®nlocuim cu "inimÄƒ". Sau Ã®n legal, "shall" tradus greÈ™it cu "ar trebui" Ã®l Ã®nlocuim cu "va". Aceste reguli fine pot fi È›inute Ã®ntr-un fiÈ™ier de mapping (JSON de tip "cuvant_incorect" -> "cuvant_corect" per domeniu).
â€¢	VerificÄƒri de calitate: ImplementÄƒm È™i un scoring de calitate de bazÄƒ: de pildÄƒ, comparÄƒm lungimea textului original vs tradus sau folosim o metricÄƒ de similaritate (fuzzy). Putem verifica dacÄƒ toate numerele din original apar Ã®n traducere (ex: dacÄƒ "2023" lipseÈ™te din traducere e o problemÄƒ). De asemenea, dacÄƒ sunt nume proprii sau acronime, verificÄƒm cÄƒ s-au pÄƒstrat (sau transcris corect). Putem face o listÄƒ de cuvinte care nu ar trebui traduse (nume, acronime) È™i sÄƒ verificÄƒm cÄƒ ele apar Ã®n output; altfel scÄƒdem scorul. Un quality_score simplu (0-100) poate fi calculat pe baza acestor heuristici. Acest scor Ã®l putem loga sau afiÈ™a (intern) ca sÄƒ È™tim cÃ¢t de sigurÄƒ e traducerea. DacÄƒ scorul e foarte mic, putem chiar decide sÄƒ Ã®ncercÄƒm traducerea cu al doilea motor (fallback) È™i sÄƒ alegem varianta cu scor mai bun â€“ deÈ™i asta e opÈ›ional È™i poate creÈ™te timpul.
â€¢	Context enforcement final: Rezultatul final, dupÄƒ post-procesare, ar trebui sÄƒ reflecte cÃ¢t mai fidel contextul dorit. Traducerea specializatÄƒ astfel obÈ›inutÄƒ va fi livratÄƒ clientului. Vom marca Ã®n sistem cÄƒ acel job a fost tradus cu contextul X, poate salvÄƒm atÃ¢t varianta brutÄƒ cÃ¢t È™i varianta ajustatÄƒ â€“ util dacÄƒ vrem ulterior sÄƒ vedem ce a modificat post-procesarea.
Prin aceste tehnici (prompting È™i post-editare automatÄƒ), motorul de traducere va produce texte mult mai adecvate contextului specializat. Avantajele aÈ™teptate sunt menÈ›ionate È™i Ã®n analiza de design: +30% acurateÈ›e È™i sensuri corecte pentru termeni tehnici, stil adaptat formal/informal unde e cazul[25][3]. Ãn plus, realizÄƒm asta fÄƒrÄƒ a plÄƒti pentru un API special de context â€“ folosim la maxim capacitÄƒÈ›ile gratuit disponibile ale motoarelor existente, completate de inteligenÈ›a noastrÄƒ localÄƒ.
3.3 Pricing DiferenÈ›iat Ã®n FuncÈ›ie de Context (Smart Pricing 1.0)
â€¢	CoeficienÈ›i pe domeniu: Vom implementa un sistem de calcul al costului dinamic al traducerii, care È›ine cont de domeniul (contextul) documentului. Ideea este cÄƒ traducerile specializate (medical, juridic, tehnic) vor fi taxate puÈ›in mai mult decÃ¢t cele generale, datoritÄƒ complexitÄƒÈ›ii È™i valorii adÄƒugate[30]. Conform strategiei business, preÈ›ul de bazÄƒ stabilit este ~7 RON/paginÄƒ pentru general È™i poate urca la ~8-9 RON/paginÄƒ pentru contexte complexe[31]. Vom modela acest lucru prin coeficienÈ›i. De exemplu:
â€¢	Domeniu general: coeficient 1.0 (preÈ› de bazÄƒ).
â€¢	Juridic/Medical: coeficient 1.2 (adicÄƒ +20% faÈ›Äƒ de bazÄƒ).
â€¢	Tehnic/IT: coeficient 1.1 (+10%).
â€¢	Business/Marketing: coeficient 1.1.
â€¢	Academic/EducaÈ›ional: coeficient 1.05, etc.
Valori exacte vor fi puse Ã®n fiÈ™ierul de configurare (ex: pricing.yaml). Aceste multipliers reflectÄƒ È™i sugestiile GPT-5 (ex: medical ~1.3, OCR ~1.35, expres ~1.7 dacÄƒ am include È™i factori de urgenÈ›Äƒ)[32][21], deÈ™i pentru MVP vom folosi doar componenta de domeniu acum, restul (layout, SLA) fiind eventual pe viitor.
â€¢	Formula de calcul: Formula generalÄƒ sugeratÄƒ este:
 	 \text{preÈ›} = \text{nr_cuvinte} \times \text{tarif_bazÄƒ_per_cuvÃ¢nt} \times \text{coef_domeniu} \times \text{coef_layout} \times \text{coef_SLA}
 	[21]. Ãn implementarea actualÄƒ (Batch 1), vom considera layout = 1 (nu diferenÈ›iem cost dacÄƒ e PDF scanat sau nu, deocamdatÄƒ) È™i SLA = 1 (nu avem Ã®ncÄƒ opÈ›iuni de livrare rapidÄƒ). Astfel se reduce la:
 	 \text{preÈ›} = \text{nr_cuvinte} \times \text{tarif_bazÄƒ} \times \text{coeficient\_domeniu}.
 	Vom stabili tarif_bazÄƒ astfel Ã®ncÃ¢t pentru general sÄƒ iasÄƒ ~7 RON/pag. DacÄƒ considerÄƒm 300 cuvinte = 1 paginÄƒ, 7 RON/pag implicÄƒ ~0.0233 RON/cuvÃ¢nt. Putem rotunji la 0.025 RON/cuvÃ¢nt tarif de bazÄƒ (25 bani/100 de cuvinte). Atunci pentru domeniu medical (coef 1.2) rezultÄƒ ~0.03 RON/cuvÃ¢nt, adicÄƒ ~9 RON/pag â€“ Ã®n linie cu planul. Vom preciza tariful exact Ã®n config pentru transparenÈ›Äƒ.
â€¢	Calculator de preÈ› instant: Pe front-end (pagina web), vom adÄƒuga un calculator dinamic care afiÈ™eazÄƒ clientului costul estimat imediat ce È™tim numÄƒrul de cuvinte È™i domeniul:
â€¢	DupÄƒ upload, backend-ul va conta cuvintele (componentÄƒ deja existentÄƒ Ã®n procesor) È™i va transmite valoarea cÄƒtre front (poate deja se Ã®ntÃ¢mplÄƒ). Vom extinde sÄƒ transmitÄƒ È™i preÈ›ul calculat sau factorii.
â€¢	Alternativ, putem face calculul direct Ã®n JavaScript: la upload, front-end-ul primeÈ™te numÄƒrul de cuvinte È™i apoi pe baza domeniului selectat aplicÄƒ formula. Pentru asta, putem expune coeficienÈ›ii È™i preÈ›ul per cuvÃ¢nt Ã®ntr-un obiect JS (sau ca datÄƒ Ã®ntr-un atribut).
â€¢	Simplu: includem Ã®n pagina generatÄƒ un snippet de genul:
 	const base_rate = 0.025;
const domain_multipliers = { general: 1.0, juridic: 1.2, medical: 1.2, tehnic: 1.1, it: 1.1, economic: 1.1, academic: 1.0, sport: 1.0 };
// Apoi cand avem word_count:
let price = (word_count * base_rate * domain_multipliers[selectedDomain]).toFixed(2);
document.getElementById('price_display').innerText = price + " RON";
â€¢	Astfel, cÃ¢nd utilizatorul schimbÄƒ dropdown-ul de domeniu, preÈ›ul se recalculeazÄƒ instant. Acest preview pricing Ã®i oferÄƒ transparenÈ›Äƒ È™i poate influenÈ›a alegerea (ex: dacÄƒ vede cÄƒ "general" e mai ieftin cu 10%, ar putea totuÈ™i opta pentru "general", dar atunci calitatea scade â€“ decizie a lui).
â€¢	A/B testing pricing: Vom lÄƒsa loc pentru experimentare â€“ de ex. definim douÄƒ scheme de preÈ›uri (Strategy A È™i B) pentru a vedea care performeazÄƒ mai bine comercial. Ãn config putem avea doi seturi de coeficienÈ›i sau tarife. Implementarea:
â€¢	Fiecare nou utilizator (sesiune nouÄƒ) este aleator asignat unei strategii (A sau B). Putem face if random() < 0.5 then strategy=A else B È™i stocÄƒm Ã®n session['pricing_strategy'].
â€¢	Strategia A ar putea fi cea descrisÄƒ (ex: base 0.025, coef medical 1.2), Strategia B poate avea base mai mic È™i coeficienÈ›i mai mari, sau viceversa, ori chiar fÄƒrÄƒ diferenÈ›iere pe context (ca test extrem).
â€¢	Front-end-ul va folosi valorile conform strategiei curente.
â€¢	Noi vom colecta date despre conversii sub fiecare strategie (vezi mai jos) È™i putem astfel determina dacÄƒ pricing-ul diferenÈ›iat aduce mai mult profit sau nu.
â€¢	La nevoie, putem activa/dezactiva A/B din config (ex: un flag enable_ab_test: true È™i definirea ambelor profile de preÈ›).
â€¢	Analytics Ã®n SQLite: Vom crea o tabelÄƒ quotes sau orders (dacÄƒ nu existÄƒ deja una) unde vom salva informaÈ›ii despre fiecare ofertÄƒ de preÈ› È™i rezultat:
â€¢	CÃ¢mpuri: id, timestamp, user_email (dacÄƒ disponibil), words, domain, price_offered, strategy, conversion.
â€¢	conversion poate fi boolean sau o datÄƒ â€“ dacÄƒ oferta s-a concretizat Ã®ntr-o comandÄƒ plÄƒtitÄƒ. IniÈ›ial, la generarea ofertei (cÃ¢nd user vede preÈ›ul È™i face preview), conversion=0. DacÄƒ userul plÄƒteÈ™te ulterior, atunci la confirmarea plÄƒÈ›ii actualizÄƒm acea intrare marcÃ¢nd conversion=1.
â€¢	Legarea se poate face printr-un ID de sesiune sau token comanda. De exemplu, generÄƒm un order_id la upload, Ã®l includem Ã®n sesiune È™i-l propagÄƒm È™i cÄƒtre formularul de platÄƒ; la webhook Stripe cÃ¢nd vine confirmarea, gÄƒsim recordul È™i marcÄƒm convertit.
â€¢	Pe baza acestor date, ulterior putem calcula rata de conversie pentru fiecare categorie de preÈ›: dacÄƒ observÄƒm cÄƒ strategia A converteÈ™te 10% È™i B doar 5%, alegem A permanent; sau dacÄƒ domeniul "medical" cu preÈ› mai mare are conversii mult mai scÄƒzute, poate trebuie redus coeficientul.
â€¢	Aceste analytics vor fi eventual extrase Ã®n rapoarte (script separat) â€“ ex: numÄƒr de comenzi per domeniu, venit total per domeniu, etc.
Ãn ansamblu, Smart Pricing 1.0 asigurÄƒ cÄƒ monetizÄƒm corect valoarea adÄƒugatÄƒ a traducerilor specializate[21]. ClienÈ›ii vÄƒd clar diferenÈ›a (preview-ul context vs general) È™i pot decide informat, iar noi ne asigurÄƒm venituri mai mari unde e cazul, fÄƒrÄƒ a exclude opÈ›iunea mai ieftinÄƒ. AceastÄƒ diferenÈ›iere competitivÄƒ a fost subliniatÄƒ ca un factor cheie de creÈ™tere a veniturilor (+25-40% conform estimÄƒrilor)[33].
3.4 Previzualizare (Preview) cu Watermark â€œNEPLÄ‚TITâ€
â€¢	Generare preview 200 cuvinte: La upload-ul unui document, sistemul va produce automat o previzualizare gratuitÄƒ a traducerii â€“ primele ~200 de cuvinte traduse[34]. Acest preview permite clientului sÄƒ vadÄƒ calitatea traducerii Ã®nainte de platÄƒ. Implementarea concretÄƒ: dupÄƒ ce textul e extras È™i contorizat, luÄƒm primele N caractere/ cuvinte din text (pÃ¢nÄƒ la sfÃ¢rÈ™itul propoziÈ›iei apropiat) È™i rulÄƒm prin motorul de traducere exact ca la o traducere normalÄƒ (incluzÃ¢nd adaptarea la context dacÄƒ contextul e selectat). RezultÄƒ un fragment tradus.
â€¢	Watermark vizual â€œPREVIEW - NEPLÄ‚TITâ€: Pentru ca acest fragment sÄƒ nu poatÄƒ fi utilizat ca atare Ã®n scopuri oficiale È™i sÄƒ indice clar cÄƒ este doar un preview, vom suprapune un watermark text vizibil. Modalitatea depinde de cum prezentÄƒm preview-ul:
â€¢	Ãn pagina web (HTML): Putem afiÈ™a textul tradus Ã®ntr-un container <div> peste care, folosind CSS position: absolute; opacity: 0.3; transform: rotate(-30deg);, desenÄƒm repetitiv textul "PREVIEW - NEPLÄ‚TIT". Practic, facem un element overlay pe tot <div>-ul cu conÈ›inut, cu pointer-events none, care conÈ›ine watermark-ul (de ex. Ã®ntr-un <canvas> sau ca text repetat). Astfel utilizatorul poate citi textul, dar dacÄƒ Ã®ncearcÄƒ sÄƒ-l copieze, fie copiazÄƒ È™i watermark-ul (dacÄƒ e parte a textului), fie Ã®n cazul overlay-lui pur poate totuÈ™i copia textul dedesubt. Pentru a Ã®mpiedica extragerea complet curatÄƒ, putem insera cuvintele "PREVIEW" direct Ã®n textul tradus la fiecare cÃ¢teva propoziÈ›ii. O idee: inserÄƒm sintagma "[PREVIEW]" Ã®ntre paranteze pÄƒtrate la fiecare 2-3 propoziÈ›ii Ã®n text. Aceasta se poate elimina manual, dar e incomod pentru un fragment mai lung.
â€¢	Ãn fiÈ™ier descÄƒrcabil (PDF/DOCX): DacÄƒ oferim posibilitatea de descÄƒrcare a preview-ului, ar fi ideal sÄƒ fie un PDF cu watermark. Putem genera un PDF simplu din text folosind o bibliotecÄƒ ca ReportLab (free) sau chiar pandoc/LaTeX dacÄƒ avem, dar ReportLab e ok. Vom pune textul tradus pe paginÄƒ È™i vom desena deasupra (pe layer-ul PDF) textul "PREVIEW - NEPLÄ‚TIT" diagonal È™i transparent de mai multe ori. Ãn Word (DOCX) e puÈ›in mai complicat de generat watermark, dar Python-docx permite inserarea unei forme sau text Ã®n header ca watermark.
â€¢	Cel mai simplu: generÄƒm PDF cu watermark. Apoi pe front-end, butonul "DescarcÄƒ preview" oferÄƒ acel PDF. PDF-ul fiind ne-editabil uÈ™or, watermark-ul rÄƒmÃ¢ne protejat.
â€¢	ComparaÈ›ie standard vs. context: O funcÈ›ionalitate de previzualizare comparativÄƒ poate evidenÈ›ia clientului beneficiile contextului specializat:
â€¢	DacÄƒ userul a ales (sau auto-detectat) un domeniu specializat, putem genera douÄƒ versiuni ale preview-ului:
a.	Traducere standard (general) â€“ adicÄƒ fÄƒrÄƒ prompt special, ca È™i cum contextul ar fi "General".
b.	Traducere contextualizatÄƒ â€“ cu adaptÄƒrile de la 3.2.
â€¢	Apoi Ã®n interfaÈ›Äƒ putem afiÈ™a fie una sub alta, fie Ã®ntr-un tab switcher: "Previzualizare Standard" vs "Previzualizare cu Context Medical". Eventual evidenÈ›iem diferenÈ›ele: de exemplu, colorÄƒm cu verde cuvintele care diferÄƒ Ã®ntre versiuni sau folosim un diff highlight simplu. DacÄƒ diferenÈ›ele sunt semnificative (de obicei la termeni tehnici), clientul va vedea concret cÄƒ versiunea contextualizatÄƒ e mai bunÄƒ (sperÄƒm).
â€¢	DacÄƒ domeniul este General oricum, putem omite comparaÈ›ia (sau afiÈ™a doar o singurÄƒ variantÄƒ cu notÄƒ cÄƒ pt general nu existÄƒ diferenÈ›e).
â€¢	AceastÄƒ funcÈ›ie are È™i rol de marketing: aratÄƒ ce face contextul specializat. Ar fi util mai ales dacÄƒ vom oferi Industry Packs premium â€“ ex: poate Ã®n varianta gratuitÄƒ ar primi traducerea generalÄƒ, È™i li se aratÄƒ cum ar arÄƒta dacÄƒ ar plÄƒti pack-ul medical. Dar Ã®n cazul de faÈ›Äƒ, cum oricum oferim context in preÈ›, e mai mult pentru convingere È™i transparenÈ›Äƒ.
â€¢	Download sample: DupÄƒ afiÈ™area preview-ului Ã®n browser, oferim opÈ›iunea de download ("DescarcÄƒ acest preview ca PDF"). Cum am descris, generÄƒm PDF-ul cu watermark. Alternativ, chiar direct butonul poate trimite header de PDF la browser. Astfel, userul poate arÄƒta È™i altcuiva (ex: decidentului) calitatea traducerii, avÃ¢nd totodatÄƒ watermark care indicÄƒ cÄƒ nu e finalÄƒ.
â€¢	Tracking conversie: Vom folosi datele despre preview Ã®n analiza de conversie din 3.3. AdicÄƒ atunci cÃ¢nd generÄƒm preview, Ã®nregistrÄƒm asta (event preview_generated Ã®n log audit + Ã®n tabela quotes punem price, domain etc.). DacÄƒ userul nu finalizeazÄƒ comanda, vom È™ti. Putem chiar adÄƒuga Ã®n DB un flag preview_shown=1 pentru comenzi. Ãn rapoarte, putem verifica cÃ¢È›i useri au renunÈ›at dupÄƒ preview â€“ de exemplu, dacÄƒ renunÈ›Äƒ mulÈ›i, poate calitatea a fost nesatisfÄƒcÄƒtoare sau preÈ›ul prea mare.
â€¢	De asemenea, putem track-ui cÃ¢t timp a stat pe pagina de preview sau dacÄƒ a descÄƒrcat PDF-ul (dacÄƒ accesarea link-ului de download genereazÄƒ un log). Aceste micro-analitice pot ajuta sÄƒ identificÄƒm interesul: dacÄƒ cineva a descÄƒrcat preview dar nu a cumpÄƒrat, poate l-a folosit Ã®n alt scop? (sau am pus prea mult din traducere? 200 cuvinte e ~ o jumate de paginÄƒ, e ok).
â€¢	Oricum, conversia finalÄƒ (platÄƒ efectuatÄƒ) am discutat cÄƒ o marcÄƒm. Putem calcula preview-to-sale conversion rate.
Implementarea acestei previzualizÄƒri cu watermark consolideazÄƒ Ã®ncrederea clientului Ã®n serviciu (vÄƒd ce primesc) È™i totodatÄƒ protejeazÄƒ afacerea de abuz (clientul nu primeÈ™te tot textul fÄƒrÄƒ platÄƒ). Este o componentÄƒ deja prevÄƒzutÄƒ ca esenÈ›ialÄƒ Ã®n sistem[34] È™i cu watermarking profesional conform planificÄƒrii iniÈ›iale[35].
Testele unitare vor verifica cÄƒ watermark-ul chiar se aplicÄƒ (ex: dupÄƒ generarea preview, stringul "PREVIEW" apare Ã®n text/PDF) È™i cÄƒ preview-ul e limitat ca lungime.
3.5 â€œClient Memoryâ€ â€“ Memorie de Traduceri Ã®n SQLite
â€¢	Database local pentru memorie: Vom construi o memorie de traducere light (TM-Lite basic) stocatÄƒ Ã®n SQLite, care sÄƒ reÈ›inÄƒ fragmente traduse anterior pentru fiecare client. Ideea este sÄƒ Ã®nvÄƒÈ›Äƒm din traducerile trecute astfel Ã®ncÃ¢t viitoarele traduceri pentru acelaÈ™i client sÄƒ fie consistente terminologic È™i adaptate preferinÈ›elor sale. Acest concept de Translation Memory a fost evidenÈ›iat ca inovativ (ADN #5) Ã®n planul GPT-5[36] â€“ noi implementÄƒm o versiune simplificatÄƒ acum, fÄƒrÄƒ interfaÈ›Äƒ de aprobare dar cu efect de personalizare.
â€¢	Structura TM: Vom crea o tabelÄƒ SQLite, de exemplu translation_memory, cu coloe precum:
â€¢	user_id (poate email sau un hash al email-ului clientului, pentru confidenÈ›ialitate),
â€¢	source_text (textul original al segmentului),
â€¢	translated_text (traducerea finalÄƒ livratÄƒ),
â€¢	domain (domeniul/contextul, dacÄƒ relevant terminologic),
â€¢	eventual created_at.
â€¢	AceastÄƒ tabelÄƒ va stoca segmente de propoziÈ›ie sau fraze scurte. Nu vom stoca Ã®ntreg documentul ca o intrare (cÄƒci nu ajutÄƒ la reutilizare parÈ›ialÄƒ).
â€¢	Segmentare propoziÈ›ii: CÃ¢nd procesÄƒm o traducere finalÄƒ pentru livrare, vom sparge textul Ã®n propoziÈ›ii (folosind NLTK sent_tokenize sau simple split pe punct/interogaÈ›ie/exclamaÈ›ie, È›inÃ¢nd cont de prescurtÄƒri). Apoi pentru fiecare propoziÈ›ie (sau poate paragraf scurt) vom salva Ã®n memorie perechea original-tradus. Ca optimizare, putem filtra segmentele foarte scurte (ex: <3 cuvinte, care pot fi comune È™i nu ne ajutÄƒ).
â€¢	DacÄƒ textul e foarte lung, stocarea fiecÄƒrei propoziÈ›ii s-ar putea sÄƒ ducÄƒ la o memorie mare, dar SQLite poate gestiona È™i zeci de mii de rÃ¢nduri fÄƒrÄƒ probleme. Oricum, memoriile vor fi per client, deci fragmentate.
â€¢	ÃnvÄƒÈ›are din alegeri: Client memory va acÈ›iona È™i ca un profil de preferinÈ›e:
â€¢	DacÄƒ observÄƒm cÄƒ un anumit client foloseÈ™te mereu contextul "Medical", putem sÄƒ setÄƒm implicit acel context pentru viitoarele sale comenzi (pre-selectare Ã®n dropdown) â€“ asta poate fi consideratÄƒ o preferinÈ›Äƒ Ã®nvÄƒÈ›atÄƒ. Putem avea o tabelÄƒ user_preferences cu user, preferred_domain, preferred_tone etc., actualizatÄƒ dupÄƒ fiecare comandÄƒ (ex: dacÄƒ 3 traduceri la rÃ¢nd au fost Medical, setÄƒm preferinÈ›a Medical).
â€¢	DacÄƒ ar exista opÈ›iuni de stil (ex: formal vs informal default), le-am putea memora la fel.
â€¢	O altÄƒ preferinÈ›Äƒ implicÄƒ terminologia: dacÄƒ la o comandÄƒ userul a fÄƒcut observaÈ›ii (de ex printr-un sistem de feedback) cÄƒ preferÄƒ un anumit termen, ideal am reÈ›ine. Ãn lipsa interacÈ›iunii directe, ne bazÄƒm doar pe ce traduceri a acceptat (presupunem cÄƒ cele livrate au fost ok).
â€¢	Reutilizare automatÄƒ a traducerilor: CÃ¢nd un client Ã®ncarcÄƒ un document nou, vom Ã®ncerca sÄƒ reutilizÄƒm segmente din memoria lui:
â€¢	DupÄƒ ce extragem textul documentului, Ã®l vom parcurge propoziÈ›ie cu propoziÈ›ie. Pentru fiecare propoziÈ›ie, cÄƒutÄƒm Ã®n translation_memory dacÄƒ acelaÈ™i source_text existÄƒ deja pentru acel user_id. DacÄƒ da, Ã®nseamnÄƒ cÄƒ am tradus exact acea propoziÈ›ie Ã®n trecut. Putem atunci Ã®nlocui direct traducerea cu cea din memorie, Ã®n loc sÄƒ o retraduce motorul AI. Acest lucru asigurÄƒ consistenÈ›Äƒ 100% cu traducerile anterioare (dacÄƒ atunci a fost corectÄƒ È™i acceptatÄƒ).
â€¢	DacÄƒ gÄƒsim potrivire parÈ›ialÄƒ (propoziÈ›ii foarte asemÄƒnÄƒtoare dar nu identice), nu vom Ã®nlocui automat (risc de nepotrivire). Dar putem marca acea propoziÈ›ie ca potenÈ›ial candidat È™i eventual sÄƒ evidenÈ›iem Ã®ntr-un raport de post-procesare pentru translator uman (dacÄƒ ar fi). Ãn contextul complet automat, momentan vom ignora fuzzy match pentru simplitate, focus pe exact match.
â€¢	CÄƒutarea exactÄƒ Ã®n SQLite este rapidÄƒ dacÄƒ indexÄƒm source_text. Putem folosi interogare SELECT translated_text FROM translation_memory WHERE user_id=? AND source_text=?. Pentru fuzzy, am putea utiliza full-text search FTS5 È™i un algoritm de similaritate, dar lÄƒsÄƒm ca posibil upgrade viitor (TM-Lite extins).
â€¢	DupÄƒ aceastÄƒ Ã®nlocuire, textul (sau segmentele) rÄƒmase netraduse vor fi trimise ca de obicei la DeepL/Google. Apoi vom avea un mix: unele propoziÈ›ii traduse nou, altele luate din memorie. Le combinÄƒm Ã®n ordinea originalÄƒ pentru a forma rezultatul final.
â€¢	Personalizare cu algoritmi de scor: DacÄƒ existÄƒ multiple traduceri candidate Ã®n memorie pentru acelaÈ™i text sursÄƒ (situaÈ›ie rarÄƒ - de ex. dacÄƒ acelaÈ™i string a apÄƒrut Ã®n douÄƒ documente diferite È™i poate traducerile au fost diferite din cauza contextului), va trebui sÄƒ alegem cea mai potrivitÄƒ. Putem atribui un scor de Ã®ncredere fiecÄƒrei memorii:
â€¢	Traducerile realizate cu context acelaÈ™i ca documentul curent au prioritate (dacÄƒ sursa e identicÄƒ dar una traducere era sub context Medical È™i alta sub General, iar acum tot medical context, alegem varianta Medical).
â€¢	Traducerile mai recente ar putea fi mai de Ã®ncredere â€“ deci putem lua ultima traducere (ORDER BY created_at DESC LIMIT 1).
â€¢	Ãn viitor, dacÄƒ am avea un sistem de rating/corrections de la client, am marca Ã®n memorie cele validate vs cele doar generate. Ãn lipsa asta, presupunem toate livrate sunt ok.
â€¢	Analytics comportament: Vom colecta date È™i despre modul Ã®n care memory e folositÄƒ:
â€¢	CÃ¢te segmente au fost reutilizate Ã®ntr-o nouÄƒ traducere (ex: "20% din propoziÈ›ii traduse instant din memorie") â€“ aceste economii pot fi logate Ã®n audit (event "memory_usage" cu procent).
â€¢	DacÄƒ vom avea feedback de la user (ex: userul a suprascris totuÈ™i traducerea oferitÄƒ - asta nu prea se Ã®ntÃ¢mplÄƒ Ã®n sistemul automat decÃ¢t dacÄƒ cere revizuire manual), am putea folosi asta sÄƒ corectÄƒm memoria.
â€¢	Oricum, putem genera periodic un raport (script Python) care analizeazÄƒ tabela translation_memory: cÃ¢te intrÄƒri pe user, ce domenii, rata de reutilizare etc. Aceste informaÈ›ii pot fi salvate Ã®n JSON/CSV pentru Business Intelligence (face parte È™i din Batch 6 Analytics planificat).
Ãn esenÈ›Äƒ, Client Memory conferÄƒ sistemului o capacitate de Ã®nvÄƒÈ›are continuÄƒ din documentele anterioare ale fiecÄƒrui client, realizÃ¢nd personalizare È™i consistenÈ›Äƒ. Acest lucru duce la traduceri mai coerente È™i la fidelizarea clienÈ›ilor (ei vor È™ti cÄƒ terminologia lor preferatÄƒ va fi menÈ›inutÄƒ)[36]. DeÈ™i implementarea noastrÄƒ e de bazÄƒ, ea pune fundaÈ›ia pentru un eventual modul TM-Lite complet (cu interfaÈ›Äƒ de editare, aprobare termeni etc.)[37]. Important, totul este local, stocat Ã®n SQLite È™i folosit automat, deci fÄƒrÄƒ costuri suplimentare dar adÄƒugÃ¢nd un USP tehnologic serviciului.
ğŸ“¦ Deliverables È™i Plan de Implementare
Toate componentele de mai sus vor fi livrate sub forma unui pachet complet (cod sursÄƒ, scripturi, documentaÈ›ie) pregÄƒtit pentru self-hosting. Structura livrÄƒrii È™i artefactele incluse:
â€¢	Codul sursÄƒ complet (Python + Frontend): Vom furniza Ã®ntregul proiect Ã®ntr-o structurÄƒ organizatÄƒ (de ex. similar cu cea din documentaÈ›ia finalÄƒ[38]). Codul va include:
â€¢	ActualizÄƒri Ã®n modulul Flask principal (backend/app.py È™i rutele) pentru a integra webhook-ul Stripe securizat, upload-ul local, portalul DSAR È™i rate-limiter-ul.
â€¢	Noi module Python: ex. security.py (pentru HMAC verificaÈ›ie È™i rate limit middleware), dsar_service.py (pentru logica de export/È™tergere date), memory.py (pentru funcÈ›ii de memorare È™i reutilizare traduceri), pricing.py (cu formula de calcul preÈ›).
â€¢	ModificÄƒri la translation_service.py (adaptare context prompt È™i post-procesare), document_processor.py (pentru a apela detectarea contextului È™i a segmenta textul pt memory), payment_service.py (integrare idempotency webhook).
â€¢	Frontend: fiÈ™ierul HTML (frontend/index.html) va fi actualizat cu dropdown de context, afiÈ™are preÈ› dinamic È™i secÈ›iune DSAR (sau link cÄƒtre portal DSAR). De asemenea, vom include un CSS cu stilul watermark È™i eventual pagini suplimentare (frontend/dsar.html pentru confirmÄƒri).
â€¢	Fiecare fiÈ™ier sursÄƒ va conÈ›ine comentarii detaliate Ã®n limba englezÄƒ (sau romÃ¢nÄƒ, dupÄƒ preferinÈ›Äƒ) explicÃ¢nd logica, pentru uÈ™urinÈ›a mentenanÈ›ei.
â€¢	Baza de date SQLite + scripturi migrare: Vom furniza un fiÈ™ier schema.sql sau migrÄƒri incremental (dacÄƒ se foloseÈ™te Alembic) care sÄƒ creeze/actualizeze tabelele necesare:
â€¢	Tabele noi: webhook_events (id procesat), rate_limits/banned_ips (dacÄƒ e cazul, deÈ™i acestea se pot È›ine doar Ã®n memorie È™i config), dsar_requests, translation_memory, user_preferences, quotes (sau extindere la tabelÄƒ orders existentÄƒ cu cÃ¢mpuri noi).
â€¢	Tabele existente: dacÄƒ existÄƒ orders/uploads etc., vom modifica sÄƒ adÄƒugÄƒm coloana context selectat, poate word_count, price etc. Vom documenta aceste modificÄƒri.
â€¢	Un script de migrare (ex: migrate_1_0_to_1_1.py) poate fi inclus pentru a popula noile tabele sau a migra date (dacÄƒ MVP-ul existent avea deja structuri similare).
â€¢	Baza de date va rÄƒmÃ¢ne SQLite pentru simplitate, dar codul va fi scris Ã®n aÈ™a fel Ã®ncÃ¢t comutarea la PostgreSQL (dacÄƒ se doreÈ™te Ã®n producÈ›ie mai tÃ¢rziu) sÄƒ fie relativ simplÄƒ, dat fiind cÄƒ vom folosi SQL standard È™i ORM minimal (posibil folosim direct SQLAlchemy core pentru abstracÈ›ie, dacÄƒ e deja Ã®n proiect).
â€¢	FiÈ™iere de configurare YAML/ENV: Toate setÄƒrile vor fi externalizate Ã®n fiÈ™iere de config, astfel Ã®ncÃ¢t sistemul e uÈ™or de ajustat:
â€¢	config/settings.yaml â€“ conÈ›ine chei precum: STRIPE_WEBHOOK_SECRET, DEEPL_API_KEY, GOOGLE_API_KEY, BASE_PRICE_PER_WORD, DOMAIN_COEFFICIENTS, RATE_LIMITS (ex: general:5/min, preview:2/day), WHITELIST_IPS, SMTP_SERVER + credenÈ›iale, etc.
â€¢	config/contexts.yaml â€“ definirea domeniilor È™i parametrii de traducere (prompt, formality, terminologie). Alternativ aceasta poate fi integratÄƒ Ã®n settings.yaml.
â€¢	config/keywords/ â€“ un folder cu JSON-urile de cuvinte-cheie per domeniu (dacÄƒ nu punem direct Ã®n code).
â€¢	.env.template â€“ un template pentru variabile de mediu sensibile (chei API, parole SMTP). Developerul poate copia .env.template Ã®n .env È™i completa valorile reale.
â€¢	Vom asigura cÄƒ niciun secret nu e hardcodat Ã®n cod â€“ totul vine din config sau env, facilitÃ¢nd schimbarea lor fÄƒrÄƒ modificarea codului (important pentru securitate).
â€¢	Sistem de management fiÈ™iere locale: Directorii dedicaÈ›i (uploads/, processed/, logs/, backups/) vor fi creaÈ›i È™i menÈ›ionaÈ›i Ã®n README. Vom oferi scripturi pentru curÄƒÈ›are periodicÄƒ (ex: scripts/cleanup_uploads.py) pe care userul le poate adÄƒuga Ã®n cron dacÄƒ nu folosim scheduler intern. De asemenea, logs/ È™i backups/ vor conÈ›ine fiÈ™iere compresate conform rotaÈ›iei configurate.
â€¢	Dockerfile È™i docker-compose: Vom livra un Dockerfile configurat pentru a rula aplicaÈ›ia Flask (probabil sub gunicorn pentru producÈ›ie) Ã®ntr-un container Linux. Va include toate dependenÈ›ele instalaÈ›e (Python, librÄƒrii pip, eventual NLTK data pre-downloaded, etc.). De asemenea, un docker-compose.yml va fi inclus, definind serviciile:
â€¢	web (containerul Flask),
â€¢	redis (container oficial Redis, pentru rate limiting),
â€¢	nginx (opÈ›ional, dacÄƒ dorim sÄƒ servim cu un reverse proxy din start; putem include configurarea lui pentru SSL),
â€¢	eventual un serviciu worker (dacÄƒ folosim Celery sau altceva pentru task-uri asincrone, dar Ã®n MVP probabil nu e nevoie, totul e sync).
â€¢	Compose-ul va lega volume pentru uploads/ È™i db.sqlite astfel Ã®ncÃ¢t datele sÄƒ persiste È™i sÄƒ poatÄƒ fi accesate/backupate uÈ™or de pe host.
â€¢	Astfel, un utilizator poate rula docker-compose up -d È™i are Ã®ntregul sistem pornit (self-hosted). Important: documentaÈ›ia va specifica cum sÄƒ introducÄƒ Ã®n .env cheile necesare Ã®nainte de pornire.
â€¢	Testare unitarÄƒ (unittest): Vom furniza un set de teste de bazÄƒ (testing/test_suite.py È™i eventual teste separate pe module):
â€¢	Teste pentru verify_stripe_signature() (cu un payload È™i secret cunoscut, sÄƒ vedem cÄƒ valida corect È™i cÄƒ respinge la secret greÈ™it sau timestamp expirat).
â€¢	Teste pentru rate limiting logic (simuleazÄƒ 6 cereri de la acelaÈ™i IP È™i verificÄƒ cÄƒ a 6-a e blocatÄƒ).
â€¢	Teste pentru upload validator (Ã®ncarcÄƒ un fiÈ™ier dummy .exe renumit .pdf È™i verificÄƒ cÄƒ e respins).
â€¢	Test pentru funcÈ›ia de detectare context (dÄƒ un text medical È™i vede cÄƒ returneazÄƒ "Medical" peste threshold).
â€¢	Test pentru pricing (calculeazÄƒ preÈ› pt X cuvinte Ã®n domeniu Y È™i verificÄƒ formula).
â€¢	Test pentru memory reuse (populeazÄƒ memoria cu o propoziÈ›ie È™i vede cÄƒ la traducerea unui text ce conÈ›ine propoziÈ›ia aceea, outputul conÈ›ine traducerea memoratÄƒ).
â€¢	Test pentru DSAR export logic (insereazÄƒ date de test pentru un email, cere export È™i vede cÄƒ zip-ul conÈ›ine fiÈ™ierele È™i CSV-urile aÈ™teptate).
â€¢	Aceste teste asigurÄƒ cÄƒ componentele cheie merg È™i previn regresii. Le vom documenta rata de acoperire (vizÄƒm >80% funcÈ›ii critice acoperite).
â€¢	DocumentaÈ›ie de utilizare (README): Un fiÈ™ier README.md detaliat va fi inclus, explicÃ¢nd:
â€¢	Setup iniÈ›ial: cum se copiazÄƒ .env È™i se pun cheile Stripe, DeepL etc., cum se configureazÄƒ (ex: adÄƒugarea IP-urilor whitelist, ajustarea coeficienÈ›ilor de preÈ›).
â€¢	Instalare localÄƒ: fie modul manual (instalare Python 3.X, pip install -r requirements.txt, NLTK download punkt, pornire python backend/app.py), fie modul Docker (docker-compose up). Vom oferi ambele opÈ›iuni.
â€¢	Utilizare È™i flux: cum se foloseÈ™te aplicaÈ›ia â€“ de la upload fiÈ™ier la platÄƒ, unde se gÄƒsesc fiÈ™ierele, ce primeÈ™te userul.
â€¢	ExplicaÈ›ii configurÄƒri securitate: de ex: cum sÄƒ schimbi pragurile de rate-limit, cum sÄƒ adaugi un user premium Ã®n whitelist.
â€¢	Proceduri de mentenanÈ›Äƒ: backup la db.sqlite (poate scriem un script care face dump zilnic), rotaÈ›ie log, cum se extinde lista de cuvinte pentru context, etc.
â€¢	Self-hosting guidance: noÈ›iuni de rulare Ã®n producÈ›ie â€“ ex: recomandarea de a pune serverul Ã®n spatele Nginx (dÄƒm exemplu de config), sÄƒ foloseascÄƒ HTTPS (inclus un script Letâ€™s Encrypt eventual dacÄƒ e relevant), È™i modul de a seta variabilele de mediu pentru Docker.
â€¢	Checklist de securitate: Vom furniza un document/checklist enumerÃ¢nd toate mÄƒsurile de securitate implementate È™i recomandÄƒri pentru administratori la deploy:
â€¢	Folosirea SSL (asigurarea cÄƒ site-ul ruleazÄƒ pe HTTPS; vom include Ã®n docker-compose un exemplu cu Nginx + certificatul).
â€¢	Schimbarea cheilor implicite È™i a parolelor din config (ex: secret Stripe, API keys, secret key Flask pentru sesiuni).
â€¢	Limitarea accesului la portul Redis din exterior (Ã®n compose lÄƒsÄƒm Redis accesibil doar intern, sau daca e instalare manualÄƒ recomandÄƒm firewall blocare port 6379 extern).
â€¢	Setarea permisiunilor pe fiÈ™ierele sensibile (config, baza de date â€“ sÄƒ nu fie world-readable).
â€¢	Regular patching: menÈ›ionÄƒm versiunile de dependenÈ›e folosite (toate sunt gratuite) È™i recomandÄƒm update periodic.
â€¢	ProtecÈ›ie XSS/CSRF: notÄƒm cÄƒ folosim Flask cu template autoescape pentru output, È™i cÄƒ formularele sensibile (DSAR) vor avea token CSRF dacÄƒ e cazul (Flask-WTF poate fi integrat gratuit).
â€¢	Monitorizare: recomandÄƒm sÄƒ se monitorizeze log-urile de securitate (È™i pot folosi fail2ban pentru log-ul de ban IP de exemplu).
â€¢	Backup: sfaturi de backup regulat la SQLite È™i volume uploads, eventual folosirea scriptului de archive logs.
â€¢	Antivirus: sugerÄƒm opÈ›ional rularea unui ClamAV periodic pe folderul de upload (script separat).
Acest checklist va fi inclus probabil Ã®n README sau ca SECURITY.md. El asigurÄƒ cÄƒ cine instaleazÄƒ soluÈ›ia nu omite paÈ™i cruciali de securitate operationalÄƒ.
â€¢	Integrare completÄƒ cu knowledge base existent: Ne vom asigura cÄƒ tot ce implementÄƒm este compatibil cu planul È™i structura proiectului existent (MVP-ul de pÃ¢nÄƒ acum). Vom verifica punct cu punct cerinÈ›ele extrase din knowledge base È™i le-am acoperit pe toate:
â€¢	Webhook HMAC + Rate limit + Upload security â€“ acoperite la Componenta 1[1][2].
â€¢	GDPR basic (retenÈ›ie, export/delete) â€“ acoperite la Componenta 2[16].
â€¢	Context specializat (detectare + adaptare) â€“ acoperit la 3.1 È™i 3.2[25][3].
â€¢	Smart Pricing + Preview watermark â€“ acoperite la 3.3 È™i 3.4[21][39].
â€¢	Memory client â€“ acoperit la 3.5 (inspirat de TM-Lite)[36].
Astfel Batch 1 (Foundation & Security + ADN #1) va fi livrat complet, Ã®ndeplinind 100% din cerinÈ›ele stabilite.
â€¢	ArhivÄƒ ZIP livrabilÄƒ: Toate fiÈ™ierele vor fi comprimate Ã®ntr-un fiÈ™ier ZIP structurat (sau direct push pe repository GitHub). Arhiva va conÈ›ine directoarele menÈ›ionate (backend/, frontend/, config/, deployment/, logs/, uploads/ etc. â€“ ultimele douÄƒ goale sau cu un README). Practic reflectÄƒ structura din documentaÈ›ia finalÄƒ[38]. Se va putea extrage È™i rula imediat conform instrucÈ›iunilor.
Cu aceste deliverables, clientul sau echipa de dezvoltare poate testa È™i lansa imediat sistemul pe infrastructura proprie, avÃ¢nd asigurate atÃ¢t funcÈ›ionalitÄƒÈ›ile cheie cÃ¢t È™i ghidajul necesar. Implementarea este robustÄƒ, gratuitÄƒ È™i la nivel enterprise, Ã®ndeplinind obiectivul de a obÈ›ine un sistem de traduceri AI self-hosted de Ã®naltÄƒ calitate, fÄƒrÄƒ costuri de licenÈ›iere sau servicii externe â€“ practic transpunÃ¢nd recomandÄƒrile GPT-5 Ã®n soluÈ›ii concrete 100% open-source[40][41].
________________________________________
[1] [2] [3] [4] [8] [9] [10] [11] [15] [16] [17] [18] [20] [21] [22] [23] [24] [25] [26] [27] [30] [31] [32] [33] [35] [36] [37] [39] [40] [41] 3.1_ideei_functii_web.md
https://drive.google.com/file/d/1zZS3HMHos75UuP_TCJXW_VC4i_ykCCMT
[5] [6] [7] Receive Stripe events in your webhook endpoint | Stripe Documentation
https://docs.stripe.com/webhooks
[12] [13] [14] [19] [28] [29] [34] [38] final_documentation.md
https://drive.google.com/file/d/1omOAawoHvg4Rj2xqtdMeSINPnIPtkwoo